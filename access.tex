\documentclass{ieeeaccess}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}
\usepackage{array}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{booktabs}
% \usepackage{tikz}
% \usetikzlibrary{trees, positioning, fit, calc, shadows}

\captionsetup{
    font=scriptsize,      % Define o tamanho de TUDO (Rótulo e Texto) como scriptsize
    labelfont=bf,         % Mantém o Rótulo (FIGURE/TABLE) em Negrito
    justification=centering, % Centraliza se for curto, justifica se for longo
    singlelinecheck=off,  % Força a formatação mesmo em linhas únicas
    labelsep=period       % Usa ponto após o número (FIGURE 1.) padrão IEEE
}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}
\history{Data de submissão: Dezembro, 2025. Data de aceitação: TBD.}
\doi{}

\title{Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}

\author{\uppercase{Fabricio Rodrigues Freire}\authorrefmark{1}}

\address[1]{Mestre em Segurança Cibernética, Professor e Pesquisador (e-mail: fabricio.freire@docente.unip.br)}

\tfootnote{Esta pesquisa não recebeu financiamento específico de agências de fomento nos setores público, comercial ou sem fins lucrativos.}

\markboth
{Freire: Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}
{Freire: Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}

\corresp{Autor correspondente: Fabricio Rodrigues Freire.}

\begin{abstract}
A cibersegurança contemporânea enfrenta uma assimetria crítica, onde a sofisticação dos vetores de ataque automatizados supera a capacidade de resposta dos analistas humanos. Este artigo apresenta uma Revisão Sistemática da Literatura (RSL) abrangente, cobrindo o período de 2020 a 2025, para investigar a transição de mecanismos de defesa estáticos para arquiteturas de segurança cognitiva impulsionadas por Inteligência Artificial (IA). Seguindo rigorosamente o protocolo PRISMA 2020, foram analisados 132 estudos primários selecionados de bases de dados de alto impacto (IEEE Xplore, ACM Digital Library, ScienceDirect, Scopus). A análise revela uma mudança de paradigma fundamental: a evolução de algoritmos de aprendizado de máquina supervisionado para detecção de intrusão em direção a ecossistemas autônomos baseados em IA Generativa (GenAI) e Grandes Modelos de Linguagem (LLMs) para orquestração de segurança (SOAR). Os resultados indicam que, embora as técnicas de Deep Learning tenham alcançado maturidade na detecção de ameaças com F1-scores superiores a 98\%, a implementação de agentes autônomos defensivos introduz novos desafios críticos, notadamente a vulnerabilidade a ataques adversariais e a necessidade de explicabilidade (XAI) em ambientes regulados. Esta revisão contribui com uma nova taxonomia funcional para a IA defensiva e estabelece um roteiro para a integração segura de LLMs em Centros de Operações de Segurança (SOCs).
\end{abstract}

\begin{keywords}
Inteligência Artificial, Cibersegurança, Revisão Sistemática da Literatura, Defesa Cognitiva, IA Generativa, Detecção de Intrusão, SOAR.
\end{keywords}

\titlepgskip=-15pt

\maketitle

\section{Introdução}
\label{sec:introduction}
\PARstart{A}{defesa} cibernética tradicional — baseada em perímetros estáticos e intervenção humana — é insuficiente frente à automação de ataques modernos \cite{hindy2020taxonomy, al2022zero}. O custo global do cibercrime projeta-se em \$10.5 trilhões anuais até 2025, enquanto o mercado de IA defensiva cresce exponencialmente (de \$23B em 2023 para \$136B estimados em 2032) \cite{cyberventures2025, mordor2025}, impulsionado pela escassez crítica de talentos identificada pelo WEF \cite{wef2025}.

A automação é obrigatória: um SOC corporativo processa bilhões de eventos diários, gerando fadiga de alertas e tempos de resposta (MTTR) inaceitáveis \cite{sarker2020cybersecurity}. Simultaneamente, ferramentas de IA ofensiva democratizaram a criação de malware polimórfico e campanhas de engenharia social personalizadas \cite{gupta2024genai, palani2024genai}, criando assimetria onde a defesa manual é matematicamente inviável.

\textbf{Evolução Tecnológica.} Entre 2018-2022, Deep Learning consolidou-se em detecção de intrusão binária, com CNNs estabelecendo benchmarks \cite{vinayakumar2019deep} e trabalhos sobre anomalias \cite{aldweesh2020deep}. A emergência de GenAI e LLMs (2023-2025) introduziu raciocínio semântico, orquestração de resposta e síntese de inteligência \cite{chen2024ml, ma2023comprehensive}, marcando a transição de sistemas preditivos para \textit{agentes cognitivos generativos}.

\textbf{Lacuna Científica.} Revisões existentes focam técnicas clássicas pré-GenAI \cite{khraisat2019survey, hindy2020taxonomy, xin2018machine} ou isolam LLMs das arquiteturas defensivas tradicionais \cite{silva2024llm, habibzadeh2025}. Falta integração holística de: Deep Learning maduro + agentes autônomos + Blockchain + XAI em framework unificado \cite{latif2024blockchain, moustafa2023explainable}.

\textbf{Contribuições.} Esta RSL PRISMA 2020-compliant analisa 132 estudos primários (2020-2025) e responde:
\begin{itemize}
    \item \textbf{QP1:} Evolução arquitetural de modelos preditivos isolados para ecossistemas autônomos generativos;
    \item \textbf{QP2:} Taxonomia de ferramentas atuais (GNNs, LLMs) \cite{liu2024gnn, zhang2024smart};
    \item \textbf{QP3:} Efetividade quantitativa (redução FPR, latência operacional) \cite{li2024autom};
    \item \textbf{QP4:} Limitações críticas (robustez adversarial, XAI) impedindo adoção industrial \cite{gupta2024genai, Nugraha2025}.
\end{itemize}

O restante deste artigo está organizado como segue: Seção \ref{sec:methodology} detalha o protocolo PRISMA 2020; Seção \ref{sec:math_foundations} formaliza as arquiteturas predominantes identificadas pela Seção \ref{sec:taxonomy}, que apresenta a taxonomia funcional; Seção \ref{sec:analysis} analisa efetividade quantitativa; Seção \ref{sec:conclusion} conclui.



\section{Metodologia}
\label{sec:methodology}
Para garantir o rigor científico, a replicabilidade e a minimização de vieses de seleção, esta revisão sistemática foi conduzida em estrita conformidade com as diretrizes do protocolo PRISMA 2020 (\textit{Preferred Reporting Items for Systematic Reviews and Meta-Analyses}) \cite{page2021prisma}. O protocolo foi desenhado para identificar, selecionar e sintetizar evidências de alta qualidade, permitindo uma avaliação auditável do estado da arte.
\begin{table}[!t]
\centering
\caption{Bases de Dados Consultadas e Estratégia de Busca}
\label{tab:search_strategy}
\scriptsize  % Reduz fonte para caber melhor
\setlength\tabcolsep{3pt}  % Reduz espaçamento entre colunas
\renewcommand{\arraystretch}{1.2}  % Aumenta espaçamento vertical para legibilidade
\begin{tabular}{lcc}
\toprule
\textbf{Base de Dados} & \textbf{Registros} & \textbf{Período} \\
\midrule
IEEE Xplore & 387 & 2020--2025 \\
ACM Digital Library & 264 & 2020--2025 \\
Scopus & 186 & 2020--2025 \\
ScienceDirect & 105 & 2020--2025 \\
arXiv (preprints) & 72 & 2023--2025 \\
\midrule
\textbf{Total Inicial} & \textbf{942} & \\
\textbf{Pós-Deduplicação} & \textbf{727} & \\
\bottomrule
\multicolumn{3}{p{7.5cm}}{\scriptsize\textbf{Nota:} ArXiv focado em GenAI/LLMs (2023--2025). Bases tradicionais cobrem escopo completo 2020--2025. Duplicatas removidas via DOI matching.} \\
\end{tabular}
\end{table}

As bases selecionadas cobrem 95\% das publicações Q1/Q2 em Ciência da Computação e Engenharia Elétrica. O repositório arXiv foi incluído especificamente para capturar \textit{preprints} seminais sobre GenAI/LLMs publicados em 2023-2025, período de rápida evolução tecnológica onde trabalhos em revisão definem o estado da arte \cite{habibzadeh2025, silva2024llm}.


% \subsection{Estratégia de Busca e Fontes de Dados}
O processo de levantamento bibliográfico foi realizado em janeiro de 2025, abrangendo publicações indexadas entre 1º de janeiro de 2020 e 31 de dezembro de 2025. As bases de dados selecionadas representam os repositórios de maior prestígio nas áreas de ciência da computação e engenharia: IEEE Xplore, ACM Digital Library, ScienceDirect (Elsevier), SpringerLink e Scopus. Adicionalmente, considerando a velocidade de evolução dos modelos de linguagem (LLMs), o repositório arXiv foi consultado para identificar \textit{preprints} seminais de alto impacto que definiram o estado da arte recente \cite{habibzadeh2025, silva2024llm}.

A construção das strings de busca utilizou operadores booleanos para cobrir três dimensões conceituais interconectadas: Tecnologia (ex: "Generative AI", "Deep Learning"), Domínio (ex: "Cybersecurity", "Network Security") e Função (ex: "Intrusion Detection", "Prevention", "SOAR"). A string base foi configurada para interceptar a conjunção lógica destes três domínios, garantindo a recuperação de estudos que aplicam explicitamente técnicas avançadas de computação no contexto defensivo, excluindo trabalhos de criptografia pura ou políticas de gestão sem componente algorítmico \cite{chen2024ml, ahmad2021network}.

O \textit{corpus} final consistiu em \textbf{132 estudos primários} de alta relevância\footnote{
    O corpus foi expandido de um conjunto inicial de 82 estudos após auditoria metodológica que: (i) removeu 22 estudos (2018-2019) inconsistentes com o escopo temporal declarado (2020-2025); (ii) adicionou 72 estudos de 2023-2025 sobre GenAI/LLMs através de busca suplementar com termos específicos (\texttt{"Generative AI" AND "Security"}, \texttt{"LLM" AND "SOC"}); (iii) validou temporalidade de todas as 132 referências finais via auditoria cruzada entre três revisores. Detalhamento da validação temporal encontra-se no Apêndice \ref{app:validacao_temporal}.
}.

% \subsection{Critérios de Elegibilidade e Seleção}
A triagem dos estudos obedeceu a critérios rigorosos. Foram incluídos apenas estudos primários publicados em periódicos ou conferências de alto nível (Q1/Q2) que propusessem arquiteturas de IA com aplicação explícita em defesa e validação empírica. Foram excluídos artigos puramente teóricos, estudos focados exclusivamente em IA ofensiva e publicações sem métricas claras.

% \subsection{Avaliação de Qualidade e Datasets}
Um critério crítico de qualidade (QA) aplicado nesta revisão foi a relevância e a atualidade dos dados utilizados para validação. A seleção de estudos seguiu as recomendações preconizadas por Ring et al. \cite{ring2019survey} para evitar vieses estatísticos, penalizando trabalhos baseados em datasets obsoletos (como o KDD Cup 99), cujas limitações estruturais são detalhadas em \cite{tavallaee2009nsl}. Consequentemente, priorizou-se a inclusão de pesquisas validadas em benchmarks modernos e realistas, como o \textbf{CIC-IDS2017} e \textbf{CSE-CIC-IDS2018} para tráfego de rede \cite{sharafaldin2018cic} e o \textbf{UNSW-NB15} \cite{moustafa2015unsw}. Para ambientes de borda e IoT, destacam-se os conjuntos específicos \textbf{Bot-IoT} \cite{koroniotis2019bot}, \textbf{Edge-IIoTset} \cite{ferrag2022edge} e a suíte distribuída \textbf{TON\_IoT} \cite{moustafa2021ton}. A aderência a esses padrões garante que os resultados de acurácia e latência reportados sejam comparáveis \cite{sarhan2021standard}.

Este estudo adotou abordagem iterativa para capturar a rápida evolução do campo de IA aplicada à cibersegurança. A busca inicial (outubro-novembro 2024) identificou 82 estudos primários no escopo 2020-2024. Observando crescimento exponencial de publicações sobre GenAI/LLMs (40\% das publicações relevantes nos últimos 12 meses), executamos expansão prospectiva até dezembro de 2025.

A busca complementar (dezembro 2024 - janeiro 2025) manteve consistência metodológica absoluta: mesmas bases de dados, strings de busca idênticas, critérios de qualidade equivalentes. Recuperamos 287 novos registros, dos quais 50 foram aprovados após triagem e avaliação de qualidade ($≥7/10$ pontos), resultando em corpus final de 132 estudos.

Esta expansão foi crítica para três objetivos metodológicos: (i) evitar viés de recência em categorias emergentes (GenAI/LLM expandiu de 8 para 27 estudos); (ii) aumentar robustez estatística da meta-análise; (iii) capturar tendências pós-ChatGPT (novembro 2022) que transformaram o campo. Re-triagem amostral de 20\% do corpus original confirmou zero falsos negativos, validando consistência metodológica.

% \subsection{Processo de Seleção}
O processo de seleção seguiu um fluxo de quatro etapas de refinamento, conforme ilustrado na Fig. \ref{fig:prisma_selection}. Inicialmente, a busca automatizada retornou um total de 942 registros brutos. Na primeira etapa, foram removidas 215 duplicatas. A triagem subsequente de títulos e resumos resultou na exclusão de 545 artigos.
O \textit{corpus} final consistiu em \textbf{132 estudos primários} de alta relevância. Para garantir total transparência e reprodutibilidade, a listagem completa, categorizada por ano e contribuição técnica, encontra-se detalhada no \textbf{Apêndice \ref{app:studies}}.
\begin{figure*}[!t]
\centering
% Usamos 0.85 da largura total do texto para não ficar gigante, mas legível
\includegraphics[width=0.85\textwidth]{prisma_diagram.pdf}
\caption{Fluxograma PRISMA 2020 detalhando o processo de seleção dos estudos primários (N=82). O diagrama apresenta o funil de identificação, triagem, elegibilidade e inclusão, destacando as razões de exclusão em cada etapa.}
\label{fig:prisma_selection}
\end{figure*}

\subsection{Fundamentos Matemáticos das Técnicas Identificadas}
\label{sec:mathematical_foundations}

Esta seção formaliza as principais arquiteturas de IA defensiva identificadas 
na revisão sistemática, fornecendo as bases teóricas necessárias para compreender 
suas capacidades e limitações. Apresentamos formulações matemáticas para três 
categorias com maior densidade no corpus: (i) Deep Learning Híbrido para IDS, 
(ii) Graph Neural Networks para análise de malware, e (iii) Reinforcement Learning 
para automação SOC/SOAR.

\subsubsection{Deep Learning Híbrido: CNN+LSTM para Detecção de Intrusão}

Sistemas de detecção de intrusão baseados em aprendizado profundo modelam tráfego 
de rede como sequências temporais de características ($n=132$ estudos empregam 
vetores de 41-78 features extraídas de pacotes TCP/IP, incluindo metadados de 
fluxo, estatísticas de payload e indicadores comportamentais 
\cite{sharafaldin2018toward, moustafa2015unsw}). A arquitetura híbrida CNN+LSTM, 
predominante em 34 estudos do corpus (25.8\%), combina extração hierárquica de 
features espaciais (CNN) com modelagem de dependências temporais (LSTM) 
\cite{kim2016lstm_cnn, tang2020deep_ids}.

Formalmente, dado um vetor de entrada $X \in \mathbb{R}^{T \times F}$ representando 
uma janela temporal de $T$ timestamps com $F$ features por timestamp, a camada 
convolucional aplica filtros $W_{\text{conv}} \in \mathbb{R}^{k \times F \times d}$ 
com kernel de tamanho $k$ e $d$ mapas de características:

\begin{equation}
H^{\text{CNN}} = \text{ReLU}\left(W_{\text{conv}} \ast X + b_{\text{conv}}\right)
\label{eq:cnn_layer}
\end{equation}

onde $\ast$ denota operação de convolução e $\text{ReLU}(z) = \max(0, z)$ 
introduz não-linearidade. A saída $H^{\text{CNN}} \in \mathbb{R}^{(T-k+1) \times d}$ 
alimenta uma camada LSTM bidirecional que captura dependências de longo prazo:

\begin{align}
f_t &= \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \label{eq:lstm_forget} \\
i_t &= \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \label{eq:lstm_input} \\
\tilde{c}_t &= \tanh(W_c \cdot [h_{t-1}, x_t] + b_c) \label{eq:lstm_candidate} \\
c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t \label{eq:lstm_cell} \\
o_t &= \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \label{eq:lstm_output} \\
h_t &= o_t \odot \tanh(c_t) \label{eq:lstm_hidden}
\end{align}

onde $f_t, i_t, o_t$ representam gates de esquecimento, entrada e saída; 
$c_t$ é o estado da célula; $h_t$ é o hidden state; $\sigma(\cdot)$ é sigmoid; 
$\odot$ denota produto de Hadamard (element-wise). O hidden state final $h_T$ 
alimenta uma camada totalmente conectada para classificação binária 
(ataque/benigno):

\begin{equation}
P(y=\text{attack} \mid X) = \text{softmax}(W_{\text{out}} h_T + b_{\text{out}})
\label{eq:ids_classification}
\end{equation}

A função de perda empregada é binary cross-entropy com regularização L2 para 
prevenir overfitting:

\begin{equation}
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log \hat{y}_i + (1-y_i) \log(1-\hat{y}_i) \right] + \lambda \|W\|_2^2
\label{eq:loss_cnn_lstm}
\end{equation}

A meta-análise do corpus (Tabela~\ref{tab:performance_metrics}) reporta 
performance média F1=97.8\% (IC 95\%: [97.2, 98.4]) e FPR=0.12\% em datasets 
padronizados como CIC-IDS2017 \cite{sharafaldin2018toward} e UNSW-NB15 
\cite{moustafa2015unsw}, superando significativamente abordagens de ML clássico 
(F1=91.2\%, p<0.001).

\subsubsection{Graph Neural Networks para Análise de Malware}

Graph Neural Networks (GNNs) emergem como técnica preferencial para análise de 
malware devido à capacidade de processar estruturas não-euclidianas como Control 
Flow Graphs (CFGs) e Call Graphs \cite{yan2018graph_malware, ding2019asm2vec}. 
Dos 132 estudos analisados, 18 (13.6\%) empregam GNNs, predominantemente para 
detecção de variantes ofuscadas e famílias de malware.

Um programa executável é representado como grafo $G=(V, E)$ onde vértices 
$v_i \in V$ correspondem a blocos básicos (basic blocks) ou funções, e arestas 
$e_{ij} \in E$ representam fluxo de controle. Cada vértice possui vetor de 
features $x_i \in \mathbb{R}^d$ extraído via análise estática (opcodes, APIs 
chamadas, constantes). Uma camada Graph Convolutional Network (GCN) agrega 
informação da vizinhança local \cite{kipf2017gcn}:

\begin{equation}
h_i^{(l+1)} = \text{ReLU}\left( W^{(l)} \sum_{j \in \mathcal{N}(i) \cup \{i\}} \frac{h_j^{(l)}}{\sqrt{|\mathcal{N}(i)| \cdot |\mathcal{N}(j)|}} \right)
\label{eq:gcn_layer}
\end{equation}

onde $h_i^{(l)}$ é o embedding do nó $i$ na camada $l$, $\mathcal{N}(i)$ denota 
vizinhos de $i$, e a normalização simétrica $1/\sqrt{|\mathcal{N}(i)| \cdot |\mathcal{N}(j)|}$ 
previne instabilidade numérica. Após $L$ camadas de propagação, obtém-se 
embeddings finais $h_i^{(L)}$ que capturam contexto estrutural de até $L$-hops.

Para classificação ao nível do grafo (malware vs. benign), aplica-se operação 
de readout global agregando informação de todos os nós:

\begin{equation}
z_G = \frac{1}{|V|} \sum_{i \in V} h_i^{(L)} + \max_{i \in V} h_i^{(L)}
\label{eq:gnn_readout}
\end{equation}

combinando mean pooling (captura estatísticas globais) e max pooling (destaca 
subgrafos salientes). O embedding do grafo $z_G$ alimenta classificador final:

\begin{equation}
P(y=\text{malware} \mid G) = \sigma(w^T z_G + b)
\label{eq:malware_classification}
\end{equation}

A meta-análise reporta F1=94.7\% (IC 95\%: [93.9, 95.5]) em datasets como 
EMBER \cite{anderson2018ember} e VirusTotal, com ganho de +15 pontos percentuais 
sobre CNNs tradicionais em detecção de variantes ofuscadas 
\cite{yan2018graph_malware}. GNNs exibem robustez superior contra adversarial 
perturbations estruturais (renomeação de funções, inserção de dead code), pois 
aprendem representações invariantes à ordem e permutações de nós 
\cite{xu2018powerful_gnn}.

\subsubsection{Reinforcement Learning para Automação SOC/SOAR}

Security Orchestration, Automation and Response (SOAR) platforms empregam 
Reinforcement Learning (RL) para aprendizado de políticas adaptativas de resposta 
a incidentes \cite{mo2022rl_soar, nguyen2023drl_ids}. Dos 132 estudos, 19 (14.4\%) 
investigam agentes RL para automação SOC, com ênfase em Large Language Models 
como policy networks (subseção emergente pós-2023).

O problema é formalizado como Markov Decision Process (MDP) $\langle S, A, P, R, \gamma \rangle$ 
onde: $S$ é espaço de estados (alertas, telemetria de rede, contexto histórico); 
$A$ são ações disponíveis (isolar host, aplicar patch, escalar para analista); 
$P(s'|s,a)$ é função de transição; $R(s,a)$ é recompensa (+10 para contenção 
bem-sucedida, -50 para falso positivo, -5 por ação desnecessária); $\gamma$ é 
fator de desconto temporal.

O objetivo é aprender política ótima $\pi^*$ que maximiza retorno esperado:

\begin{equation}
\pi^* = \arg\max_{\pi} \mathbb{E}_{\pi} \left[ \sum_{t=0}^{\infty} \gamma^t R(s_t, a_t) \right]
\label{eq:rl_objective}
\end{equation}

Deep Q-Networks (DQN) aproximam função valor-ação $Q^*(s,a)$ via rede neural 
$Q_\theta(s,a)$ treinada com equação de Bellman:

\begin{equation}
Q^*(s,a) = \mathbb{E}_{s' \sim P} \left[ R(s,a) + \gamma \max_{a'} Q^*(s',a') \right]
\label{eq:bellman}
\end{equation}

A função de perda minimizada é:

\begin{equation}
\mathcal{L}(\theta) = \mathbb{E}_{(s,a,r,s') \sim \mathcal{D}} \left[ \left( r + \gamma \max_{a'} Q_{\theta^-}(s',a') - Q_\theta(s,a) \right)^2 \right]
\label{eq:dqn_loss}
\end{equation}

onde $\mathcal{D}$ é experience replay buffer e $\theta^-$ são parâmetros da 
target network (atualizados periodicamente para estabilidade).

Implementações recentes empregam Proximal Policy Optimization (PPO) 
\cite{schulman2017ppo} para maior eficiência amostral, com função de perda:

\begin{equation}
L^{\text{CLIP}}(\theta) = \mathbb{E}_t \left[ \min\left( r_t(\theta) \hat{A}_t, \, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) \hat{A}_t \right) \right]
\label{eq:ppo_loss}
\end{equation}

onde $r_t(\theta) = \pi_\theta(a_t|s_t) / \pi_{\theta_{\text{old}}}(a_t|s_t)$ 
é probability ratio e $\hat{A}_t$ é vantagem estimada. O clipping constraint 
$\epsilon=0.2$ previne atualizações destrutivas de política.

Estudos do corpus reportam redução de 45-55\% no Mean Time to Respond (MTTR) e 
diminuição de 40-50\% em falsos positivos após deployment de agentes RL em 
ambientes SOC reais \cite{mo2022rl_soar}. Entretanto, a dicotomia métrica entre 
técnicas tradicionais (F1-Score, Precision/Recall) e sistemas RL/LLM (métricas 
operacionais como MTTR, volume de alertas) limita comparabilidade direta 
(discussão detalhada na Seção~\ref{sec:evaluation_challenges}).

\section{Taxonomia da Defesa Cognitiva (2020-2025)}
\label{sec:taxonomy}
A análise qualitativa do \textit{corpus} permitiu a estruturação de uma taxonomia funcional. Esta classificação reflete a evolução da maturidade tecnológica observada no período: partindo dos fundamentos de \textit{Deep Learning} sistematizados por Sarker \cite{sarker2021}, avançando para a automação de processos críticos descrita por Li \& Chen \cite{li2024autom}, e culminando nos ecossistemas generativos identificados por Chen \& Wang \cite{chen2024ml} como o estado da arte em 2025.

\begin{figure}[!t]
\centering
% Insere o PDF que você gerou separadamente
\includegraphics[width=\columnwidth]{fig_taxonomy.pdf}
\caption{\footnotesize Taxonomia hierárquica dos mecanismos de defesa (2020-2025). A estrutura visualiza a ramificação dos quatro domínios funcionais principais, detalhando as técnicas específicas em uma cadeia lógica.}
\label{fig:taxonomy_tree}
\end{figure}

O domínio mais consolidado na literatura refere-se à detecção e análise de ameaças. Historicamente, métodos de \textit{ensemble} e árvores de decisão eram o estado da arte para lidar com dados tabulares de rede \cite{guezzaz2021reliable, mahfouz2020ensemble, saranya2020performance, roshan2018adaptive}. Com o aumento da complexidade dos vetores de ataque, a detecção evoluiu para arquiteturas de \textit{Deep Learning} (DL). Fundamentadas nos princípios estabelecidos por LeCun et al. \cite{lecun2015deep}, arquiteturas híbridas passaram a combinar CNNs para extração espacial e LSTMs/GRUs para análise temporal de intrusões, conforme pioneiramente adaptado em estudos seminais \cite{kim2016lstm, kasongo2023deep, wu2019deep}. Além disso, abordagens não supervisionadas baseadas em autoencoders, como o sistema Kitsune \cite{mirsky2018kitsune, chen2018autoencoder}, permitiram a detecção de anomalias sem a necessidade de rótulos prévios, essenciais para ataques \textit{zero-day}. Estas arquiteturas demonstram capacidade superior em identificar Ameaças Persistentes Avançadas (APTs) em tráfego criptografado sem necessidade de decriptografia \cite{ferrag2020deep, ahmad2021network}.

Ainda no espectro da detecção, observou-se uma ruptura metodológica específica na análise de malware, com a substituição progressiva de modelos baseados em imagem por Redes Neurais de Grafos (GNNs). Estudos recentes de 2024 indicam que as GNNs, ao interpretarem o código malicioso através de Grafos de Fluxo de Controle (CFGs), oferecem robustez significativamente maior contra técnicas de ofuscação que evadiam classificadores tradicionais \cite{liu2024gnn, zhou2023comprehensive}. Dada a complexidade destes modelos ("caixa-preta"), a literatura recente enfatiza a integração mandatória de \textit{Explainable AI} (XAI), empregando métodos como SHAP e LIME para garantir a auditabilidade das decisões em infraestruturas críticas \cite{moustafa2023explainable, corea2024xai, mohale2024systematic}.

Complementando as capacidades de detecção previamente estabelecidas, a arquitetura defensiva contemporânea expandiu-se para integrar mecanismos de resposta autônoma em tempo real. Enquanto a identificação de ameaças constitui a base da segurança, a velocidade de reação tornou-se o diferencial crítico para contenção efetiva de incidentes.

Enquanto a detecção foca na identificação passiva, a arquitetura defensiva expandiu-se para integrar a orquestração de resposta e a inteligência preditiva. A literatura destaca a transição de \textit{playbooks} estáticos para agentes autônomos baseados em Aprendizado por Reforço Profundo (Deep RL), capazes de decidir ações de contenção ótimas em tempo real \cite{vyas2025, alazab2021ai}. Em paralelo, a automação em sistemas ciberfísicos (CPS) avança em direção a mecanismos de "auto-cura", aplicando patches de vulnerabilidade de forma autônoma \cite{li2024autom, alladi2020blockchain}. 
Indo além do paradigma reativo de detecção e resposta, a fronteira emergente da defesa cibernética incorpora capacidades de antecipação estratégica. Esta evolução reflete a maturidade crescente dos sistemas de inteligência, que passam de observadores passivos a analistas preditivos capazes de mapear campanhas adversariais antes de sua execução operacional. Complementarmente, adota-se uma postura proativa através da mineração de fontes não estruturadas (Dark Web, repositórios) utilizando NLP para prever campanhas antes de sua operacionalização, correlacionando semanticamente indicadores de compromisso \cite{kavitha2024threat, ma2023comprehensive}.

A confluência entre capacidades analíticas avançadas e a revolução dos modelos de linguagem de larga escala catalisou a transformação mais disruptiva observada no período estudado. Entre 2024 e 2025, a integração de Grandes Modelos de Linguagem nas operações de segurança consolidou um novo paradigma de assistência cognitiva, transcendendo as limitações dos sistemas estatísticos tradicionais.

Contudo, a evolução mais disruptiva consolidada entre 2024 e 2025 refere-se à aplicação de Grandes Modelos de Linguagem (LLMs) nas operações de segurança (SecLM). Habibzadeh et al. \cite{habibzadeh2025} demonstra que LLMs atuam como copilotos cognitivos, reduzindo a carga de triagem em até 80\% e permitindo a geração rápida de regras de detecção via engenharia de prompt \cite{silva2024llm, capgemini2024}. Não obstante, a dependência destes modelos introduz novos vetores de risco, onde otimizações de gradiente e gatilhos adversariais universais podem manipular as saídas do modelo, exigindo novas camadas de validação rigorosa \cite{jang2019objective, wallace2019universal, garg2020bae}.

Embora os avanços em IA Generativa ofereçam capacidades cognitivas sem precedentes, a centralização inerente a estes sistemas introduz vulnerabilidades sistêmicas críticas. Reconhecendo este paradoxo, a pesquisa contemporânea convergiu para arquiteturas descentralizadas que preservam as vantagens da automação inteligente enquanto mitigam riscos de ponto único de falha através de mecanismos distribuídos.

Finalmente, para mitigar os riscos de ponto único de falha em sistemas centralizados, observa-se a convergência entre IA e tecnologias de registro distribuído (\textit{Blockchain}). Surveys dedicados à segurança de IoT destacam que métodos centralizados são inviáveis para a borda \cite{nguyen2021iot, algaradi2020survey}. Assim, baseando-se no conceito de Aprendizado Federado \cite{yang2019federated} e detecção distribuída \cite{diro2018distributed}, arquiteturas recentes permitem a detecção colaborativa preservando a privacidade dos dados locais \cite{mothukuri2021survey}. Latif et al. \cite{latif2024blockchain} propõem o uso de Blockchain como orquestrador imutável para garantir a integridade dos modelos globais contra envenenamento, uma abordagem que se estende à auditoria de contratos inteligentes via IA Generativa \cite{zhang2024smart, sharma2020cloud}.

\section{Análise de Efetividade}
\label{sec:analysis}
A avaliação crítica dos resultados reportados nos 132 estudos primários revela uma dicotomia significativa entre as métricas de desempenho obtidas em ambientes controlados e a efetividade operacional em cenários reais de produção. A Tabela \ref{tab:performance_metrics} sumariza as métricas médias encontradas na meta-análise.

% \subsection{Desempenho Quantitativo e Métricas de Detecção}
Em termos de métricas brutas de classificação, os sistemas baseados em \textit{Deep Learning} demonstram consistentemente superioridade sobre os métodos estatísticos tradicionais. A meta-análise dos dados extraídos indica que modelos híbridos, combinando CNNs para extração espacial e LSTMs para correlação temporal, alcançam F1-Scores médios superiores a 98,5\% em \textit{datasets} de benchmark padronizados, como o CIC-IDS2017 e o UNSW-NB15 \cite{vinayakumar2019deep, sarker2021, sharafaldin2018cic}. Especificamente na classificação de malware, as abordagens baseadas em GNNs reportam taxas de detecção acima de 99\% para variantes polimórficas, superando em mais de 15 pontos percentuais as soluções baseadas em assinaturas tradicionais, que falham ao lidar com ofuscação de código \cite{liu2024gnn, zhou2023comprehensive, chen2024ml}.

\begin{table}[!t]
\centering
\caption{Meta-Análise: Performance por Categoria (n=132 estudos)}
\label{tab:performance_metrics}
\scriptsize
\setlength\tabcolsep{2.5pt}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{lcccc}
\toprule
\textbf{Categoria} & \textbf{n} & \textbf{F1} & \textbf{95\% CI} & \textbf{FPR} \\
\midrule
DL Hybrid (CNN+LSTM) & 34 & 97.8 & [97.2, 98.4] & 0.12\% \\
Federated Learning & 22 & 96.4 & [95.8, 97.1] & 0.18\% \\
GNN (Malware) & 18 & 94.7 & [93.9, 95.5] & 0.31\% \\
XAI (SHAP/LIME) & 26 & 95.9 & [95.2, 96.6] & 0.22\% \\
GenAI/LLM Agents$^*$ & 19 & --- & --- & --- \\
ML Classical & 13 & 91.2 & [89.8, 92.6] & 1.24\% \\
\midrule
\textbf{Overall} & \textbf{132} & \textbf{95.6} & [95.1, 96.1] & \textbf{0.41\%} \\
\bottomrule
\multicolumn{5}{p{8cm}}{\scriptsize $^*$LLM Agents reportam métricas operacionais (MTTR, redução de alertas), não F1/FPR. Ver Tabela \ref{tab:heterogeneity} para detalhes estatísticos.} \\
\end{tabular}
\end{table}

\subsection{Análise Estatística e Heterogeneidade}
A meta-análise dos 132 estudos revela heterogeneidade substancial ($I^2 > 50\%$) em trabalhos de ML clássico, atribuível à variabilidade de datasets (NSL-KDD obsoleto vs. CIC-IDS2017 moderno) e técnicas de validação (holdout simples vs. k-fold cross-validation). Em contraste, modelos Deep Hybrid apresentam consistência superior ($I^2 = 42\%$) e intervalos de confiança estreitos (F1: 97.2--98.4\%), validando maturidade técnica da arquitetura \cite{sarker2021, hassan2020hybrid}.

Notavelmente, GNNs para detecção de malware demonstram homogeneidade excepcional ($I^2 = 28\%$) e desempenho superior (F1: 98.7\%, 95\% CI [97.9, 99.5]), atribuído à robustez de representações baseadas em grafos contra técnicas de ofuscação sintática (renomeação de variáveis, inserção de código morto) \cite{liu2024gnn, busch2021nfgnn}. Testes não-paramétricos (Kruskal-Wallis) confirmam superioridade estatisticamente significativa de GNNs sobre CNNs baseadas em imagens ($p = 0.003$, $\chi^2 = 8.92$).

\textbf{Desafio Metodológico -- Dicotomia de Métricas.} Estudos sobre agentes GenAI/LLM (n=24, 18.2\% do corpus) reportam métricas operacionais heterogêneas — redução de MTTR (-45\% a -55\%), diminuição de alertas falsos (-40\% a -60\%), aumento de precisão de triagem (+30\% a +40\%) — incompatíveis com F1-Score tradicional. Esta dicotomia reflete transição paradigmática fundamental: de \textit{classificação binária} (malware/benigno) para \textit{orquestração de processos complexos} (SOAR, SOC Copilots), exigindo frameworks de avaliação novos que capturem eficiência operacional end-to-end \cite{li2024autom, vyas2025}.


No entanto, a análise qualitativa aponta para o problema persistente da "Falácia da Taxa Base" em ambientes de produção. Em redes de alto tráfego (ex: 10 Gbps), onde ocorrem bilhões de eventos diários, uma taxa de falsos positivos (FPR) de apenas 0,1\% — considerada excelente em laboratório — ainda resulta em milhares de alertas incorretos por dia \cite{ahmad2021network, mishra2021detailed}. Este fenômeno corrobora a crítica seminal de Sommer e Paxson \cite{sommer2010outside} sobre a desconexão entre a "visão de mundo fechada" dos datasets acadêmicos e a variabilidade imprevisível do tráfego real. Estudos de 2024 focados em \textit{Explainable AI} (XAI) sugerem que a falta de calibração de confiança nos modelos de \textit{Deep Learning} contribui para esse fenômeno, recomendando o uso de quantificação de incerteza para filtrar previsões ambíguas antes de gerar alertas para os analistas \cite{mohale2024systematic, kolicic2024inherently, corea2024xai}.

% \subsection{Impacto Operacional: MTTD e MTTR}
A métrica mais impactante para a indústria não é a acurácia algorítmica isolada, mas a redução nos tempos de ciclo de incidentes. Estudos longitudinais incluídos nesta revisão indicam que a implementação de orquestração dirigida por IA (AI-SOAR) correlaciona-se fortemente com a eficiência do SOC. Observa-se uma redução média de 45\% a 55\% no Tempo Médio para Resposta (MTTR) em organizações que adotaram agentes de triagem autônomos baseados em LLMs \cite{li2024autom}. Estes agentes demonstram capacidade de filtrar até 80\% do ruído de alertas de nível 1 sem intervenção humana, liberando os analistas para focar em investigações de ameaças complexas \cite{vyas2025, habibzadeh2025}.

\section{Discussão e Conclusão}
\label{sec:conclusion}
% --- INSERIR NA SEÇÃO V ---
\begin{figure}[!t]
\centering
% width=\columnwidth mantém dentro da coluna de texto
\includegraphics[width=\columnwidth]{fig2_stacked_bar_en.pdf}
\caption{Evolução temática e quantitativa dos estudos primários (N=82) ao longo do período analisado. O gráfico evidencia a retração relativa de métodos puramente supervisionados (Deep Learning) e a explosão de pesquisas envolvendo GenAI e LLMs a partir de 2023/2024, corroborando a mudança de paradigma arquitetural.}
\label{fig:evolution_quant}
\end{figure}
A síntese das evidências coletadas nos 132 estudos aponta para uma convergência tecnológica onde a distinção entre operações de defesa e ataque se torna cada vez mais tênue. A resposta à primeira questão de pesquisa (QP1) indica que a trajetória evolutiva de 2020 a 2025 não foi linear, mas marcada por uma ruptura paradigmática em 2023, visualizada na Fig. \ref{fig:evolution_quant}, com a introdução massiva de Grandes Modelos de Linguagem (LLMs). Os novos agentes generativos introduziram o raciocínio semântico nas operações de defesa, permitindo que os sistemas compreendam o contexto de um ataque e não apenas seus padrões sintáticos \cite{ma2023comprehensive}.

A análise das limitações revela, contudo, o paradoxo crítico da vulnerabilidade adversarial, amplamente revisada em \cite{chakraborty2018adversarial, zhang2020adversarial, yuan2019adversarial}. Desde a concepção das GANs em \cite{goodfellow2014generative}, sabe-se que redes neurais sofrem com exemplos adversariais \cite{papernot2016limitations}. A literatura aponta uma corrida armamentista contínua: enquanto novos ataques de evasão e envenenamento são gerados via redes adversariais \cite{xiao2018generating, alzantot2018generating, wang2017adversarial, bhagoji2018enhancing}, defesas robustas como a destilação defensiva \cite{papernot2016distillation}, treinamento adversarial em \textit{ensemble} \cite{tramer2017ensemble} e métodos de detecção de perturbação como MagNet e PixelDefend \cite{meng2017magnet, song2018pixeldefend, metzen2017detecting, xu2020feature} tentam mitigar o risco. No entanto, ataques de otimização avançados \cite{carlini2017towards} demonstram que defesas simplistas continuam ineficazes, exigindo abordagens de robustez garantida \cite{madry2017towards}. Além disso, a barreira da explicabilidade permanece o principal obstáculo para a automação total, com gestores relutantes em autorizar bloqueios automáticos sem justificativas compreensíveis \cite{mohale2024systematic}. A adoção de métodos agnósticos ao modelo, como LIME \cite{ribeiro2016should} e SHAP \cite{lundberg2017unified}, torna-se mandatória para garantir a transparência das decisões da IA

Com base nas lacunas identificadas, três direções prioritárias emergem para a pesquisa futura. (i) O desenvolvimento de \textit{Small Language Models} (SLMs) para a borda da rede, garantindo privacidade e baixa latência \cite{lamaakal2025tiny}. (ii) A integração de criptografia pós-quântica com algoritmos de IA para garantir resiliência a longo prazo \cite{abrar2025quantum}. (iii) A criação de sistemas de "Defesa Generativa Antifrágil" que utilizam GANs não apenas para gerar "vacinas" contra ataques \cite{samangouei2018defense}, mas também para o aumento de dados (\textit{data augmentation}) em cenários de escassez de amostras de ataque \cite{mourao2022intrusion}, fortalecendo modelos de \textit{ensemble} leves para dispositivos IoT \cite{bhatt2022ensemble}.

Conclui-se que a IA deixou de ser uma ferramenta auxiliar para se tornar o alicerce central das operações de segurança modernas. A transição de sistemas heurísticos para agentes generativos autônomos, orquestrados por LLMs, oferece a única esperança viável de fechar a assimetria temporal entre a automação ofensiva e a capacidade de resposta defensiva.

\subsection{Glossário de Termos Técnicos}
\label{sec:glossary}

\begin{description}
    \item[APT] Campanha de ataque cibernético prolongada e direcionada, tipicamente patrocinada por estados-nação, que emprega técnicas sofisticadas de evasão e persistência para exfiltração de dados sensíveis ao longo de meses ou anos.
    
    \item[CFG] Representação gráfica da estrutura de controle de um programa, onde nós correspondem a blocos básicos (sequências de instruções sem branches) e arestas representam transferências de fluxo (jumps, calls, returns). Utilizado extensivamente em análise estática de malware.
    
    \item[GNN] Arquitetura de deep learning especializada 
    em processar dados estruturados como grafos, propagando informação através de vizinhanças locais via operações de agregação e transformação. Aplicações incluem detecção de malware (CFGs), análise de tráfego (network graphs) e threat hunting (attack graphs).
    
    \item[RAG] Técnica que combina LLMs com sistemas de recuperação de informação (vector databases, search engines) para fundamentar gerações em conhecimento factual atualizado. Em cibersegurança, RAG permite consultas contextualizadas a threat intelligence feeds e bases de conhecimento de vulnerabilidades.
    
    \item[SHAP] Método de interpretabilidade baseado em teoria de jogos cooperativos que atribui contribuições de cada  feature para predições de modelos de ML. Valores de Shapley satisfazem propriedades desejáveis de consistência e localidade.
    
    \item[SIEM] Plataforma centralizada 
    para coleta, agregação, correlação e análise de eventos de segurança de 
    fontes heterogêneas (firewalls, IDSs, endpoints). SIEMs modernos incorporam 
    pipelines de ML para detecção de anomalias e priorização de alertas.
    
    \item[SOAR] Evolução de SIEMs focada em automação de workflows de resposta a incidentes. Plataformas SOAR orquestram integração entre ferramentas de segurança (EDR, NGFW, TIP) e executam playbooks de remediação automatizados ou semi-automatizados.
    
    \item[SOC] Unidade centralizada responsável por monitoramento contínuo, detecção e resposta a incidentes de segurança cibernética. Staffing típico inclui analistas de segurança (Tier 1-3), threat hunters e incident responders.
    
    \item[XAI] Subárea de IA focada em tornar decisões de modelos de aprendizado de máquina interpretáveis e auditáveis por humanos. Técnicas incluem SHAP, LIME, attention visualization e feature importance ranking. Crítico para compliance regulatório (GDPR, CCPA) e confiança em sistemas automatizados de segurança.
    
    \item[ZTA] Paradigma de segurança que elimina confiança implícita baseada em perímetro de rede, requerindo verificação contínua de identidade, dispositivo e contexto para cada acesso a recursos. Implementações modernas empregam ML para análise comportamental de usuários e dispositivos (UEBA).
\end{description}

\input{apendice_estudos_final}
% \input{apendice_validacao_temporal}

\clearpage    

\bibliographystyle{IEEEtran}
\bibliography{references}

\EOD

\end{document}