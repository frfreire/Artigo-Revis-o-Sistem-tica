\documentclass{ieeeaccess}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}
\usepackage{array}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{booktabs}
% \usepackage{tikz}
% \usetikzlibrary{trees, positioning, fit, calc, shadows}

\captionsetup{
    font=scriptsize,      % Define o tamanho de TUDO (Rótulo e Texto) como scriptsize
    labelfont=bf,         % Mantém o Rótulo (FIGURE/TABLE) em Negrito
    justification=centering, % Centraliza se for curto, justifica se for longo
    singlelinecheck=off,  % Força a formatação mesmo em linhas únicas
    labelsep=period       % Usa ponto após o número (FIGURE 1.) padrão IEEE
}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}
\history{Data de submissão: Dezembro, 2025. Data de aceitação: TBD.}
\doi{}

\title{Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}

\author{\uppercase{Fabricio Rodrigues Freire}\authorrefmark{1}}

\address[1]{Mestre em Segurança Cibernética, Professor e Pesquisador (e-mail: fabricio.freire@docente.unip.br)}

\tfootnote{Esta pesquisa não recebeu financiamento específico de agências de fomento nos setores público, comercial ou sem fins lucrativos.}

\markboth
{Freire: Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}
{Freire: Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}

\corresp{Autor correspondente: Fabricio Rodrigues Freire.}

\begin{abstract}
A cibersegurança contemporânea enfrenta uma assimetria crítica, onde a sofisticação dos vetores de ataque automatizados supera a capacidade de resposta dos analistas humanos. Este artigo apresenta uma Revisão Sistemática da Literatura (RSL) abrangente, cobrindo o período de 2020 a 2025, para investigar a transição de mecanismos de defesa estáticos para arquiteturas de segurança cognitiva impulsionadas por Inteligência Artificial (IA). Seguindo rigorosamente o protocolo PRISMA 2020, foram analisados \textbf{132 estudos primários} selecionados de bases de dados de alto impacto (IEEE Xplore, ACM Digital Library, ScienceDirect, Scopus). A análise revela uma mudança de paradigma fundamental: a evolução de algoritmos de aprendizado de máquina supervisionado para detecção de intrusão em direção a ecossistemas autônomos baseados em IA Generativa (GenAI) e Grandes Modelos de Linguagem (LLMs) para orquestração de segurança (SOAR). Os resultados indicam que, embora as técnicas de Deep Learning tenham alcançado maturidade na detecção de ameaças com F1-scores superiores a 98\%, a implementação de agentes autônomos defensivos introduz novos desafios críticos, notadamente a vulnerabilidade a ataques adversariais e a necessidade de explicabilidade (XAI) em ambientes regulados. Esta revisão contribui com uma nova taxonomia funcional para a IA defensiva e estabelece um roteiro para a integração segura de LLMs em Centros de Operações de Segurança (SOCs).
\end{abstract}

\begin{keywords}
Inteligência Artificial, Cibersegurança, Revisão Sistemática da Literatura, Defesa Cognitiva, IA Generativa, Detecção de Intrusão, SOAR.
\end{keywords}

\titlepgskip=-15pt

\maketitle

\section{Introdução}
\label{sec:introduction}
\PARstart{A}{defesa} cibernética tradicional — baseada em perímetros estáticos e intervenção humana — é insuficiente frente à automação de ataques modernos \cite{hindy2020taxonomy, al2022zero}. O custo global do cibercrime projeta-se em \$10.5 trilhões anuais até 2025, enquanto o mercado de IA defensiva cresce exponencialmente (de \$23B em 2023 para \$136B estimados em 2032) \cite{cyberventures2025, mordor2025}, impulsionado pela escassez crítica de talentos identificada pelo WEF \cite{wef2025}.

A automação é obrigatória: um SOC corporativo processa bilhões de eventos diários, gerando fadiga de alertas e tempos de resposta (MTTR) inaceitáveis \cite{sarker2020cybersecurity}. Simultaneamente, ferramentas de IA ofensiva democratizaram a criação de malware polimórfico e campanhas de engenharia social personalizadas \cite{gupta2024genai, palani2024genai}, criando assimetria onde a defesa manual é matematicamente inviável.

\textbf{Evolução Tecnológica.} Entre 2018-2022, Deep Learning consolidou-se em detecção de intrusão binária, com CNNs estabelecendo benchmarks \cite{vinayakumar2019deep} e trabalhos sobre anomalias \cite{aldweesh2020deep}. A emergência de GenAI e LLMs (2023-2025) introduziu raciocínio semântico, orquestração de resposta e síntese de inteligência \cite{chen2024ml, ma2023comprehensive}, marcando a transição de sistemas preditivos para \textit{agentes cognitivos generativos}.

\textbf{Lacuna Científica.} Revisões existentes focam técnicas clássicas pré-GenAI \cite{khraisat2019survey, hindy2020taxonomy, xin2018machine} ou isolam LLMs das arquiteturas defensivas tradicionais \cite{silva2024llm, habibzadeh2025}. Falta integração holística de: Deep Learning maduro + agentes autônomos + Blockchain + XAI em framework unificado \cite{latif2024blockchain, moustafa2023explainable}.

\textbf{Contribuições.} Esta RSL PRISMA 2020-compliant analisa 132 estudos primários (2020-2025) e responde:
\begin{itemize}
    \item \textbf{QP1:} Evolução arquitetural de modelos preditivos isolados para ecossistemas autônomos generativos;
    \item \textbf{QP2:} Taxonomia de ferramentas atuais (GNNs, LLMs) \cite{liu2024gnn, zhang2024smart};
    \item \textbf{QP3:} Efetividade quantitativa (redução FPR, latência operacional) \cite{li2024autom};
    \item \textbf{QP4:} Limitações críticas (robustez adversarial, XAI) impedindo adoção industrial \cite{gupta2024genai, Nugraha2025}.
\end{itemize}

O restante deste artigo está organizado como segue: Seção \ref{sec:methodology} detalha o protocolo PRISMA 2020;  \ref{sec:taxonomy} apresenta a taxonomia funcional; Seção \ref{sec:analysis} analisa efetividade quantitativa; Seção \ref{sec:conclusion} conclui.



\section{Metodologia}
\label{sec:methodology}
Para garantir o rigor científico, a replicabilidade e a minimização de vieses de seleção, esta revisão sistemática foi conduzida em estrita conformidade com as diretrizes do protocolo PRISMA 2020 (\textit{Preferred Reporting Items for Systematic Reviews and Meta-Analyses}) \cite{page2021prisma}. O protocolo foi desenhado para identificar, selecionar e sintetizar evidências de alta qualidade, permitindo uma avaliação auditável do estado da arte.
\begin{table}[!t]
\centering
\caption{Bases de Dados Consultadas e Estratégia de Busca}
\label{tab:search_strategy}
\scriptsize  % Reduz fonte para caber melhor
\setlength\tabcolsep{3pt}  % Reduz espaçamento entre colunas
\renewcommand{\arraystretch}{1.2}  % Aumenta espaçamento vertical para legibilidade
\begin{tabular}{lcc}
\toprule
\textbf{Base de Dados} & \textbf{Registros} & \textbf{Período} \\
\midrule
IEEE Xplore & 387 & 2020--2025 \\
ACM Digital Library & 264 & 2020--2025 \\
Scopus & 186 & 2020--2025 \\
ScienceDirect & 105 & 2020--2025 \\
arXiv (preprints)$^*$ & 72 & 2023--2025 \\
\midrule
\textbf{Total Inicial} & \textbf{942} & \\
\textbf{Pós-Deduplicação} & \textbf{727} & \\
\bottomrule
\multicolumn{3}{p{7.5cm}}{\scriptsize\textbf{Nota:} ArXiv focado em GenAI/LLMs (2023--2025). Bases tradicionais cobrem escopo completo 2020--2025. Duplicatas removidas via DOI matching.} \\
\end{tabular}
\end{table}

As bases selecionadas cobrem 95\% das publicações Q1/Q2 em Ciência da Computação e Engenharia Elétrica. O repositório arXiv foi incluído especificamente para capturar \textit{preprints} seminais sobre GenAI/LLMs publicados em 2023-2025, período de rápida evolução tecnológica onde trabalhos em revisão definem o estado da arte \cite{habibzadeh2025, silva2024llm}.


\subsection{Estratégia de Busca e Fontes de Dados}
O processo de levantamento bibliográfico foi realizado em janeiro de 2025, abrangendo publicações indexadas entre 1º de janeiro de 2020 e 31 de dezembro de 2025. As bases de dados selecionadas representam os repositórios de maior prestígio nas áreas de ciência da computação e engenharia: IEEE Xplore, ACM Digital Library, ScienceDirect (Elsevier), SpringerLink e Scopus. Adicionalmente, considerando a velocidade de evolução dos modelos de linguagem (LLMs), o repositório arXiv foi consultado para identificar \textit{preprints} seminais de alto impacto que definiram o estado da arte recente \cite{habibzadeh2025, silva2024llm}.

A construção das strings de busca utilizou operadores booleanos para cobrir três dimensões conceituais interconectadas: Tecnologia (ex: "Generative AI", "Deep Learning"), Domínio (ex: "Cybersecurity", "Network Security") e Função (ex: "Intrusion Detection", "Prevention", "SOAR"). A string base foi configurada para interceptar a conjunção lógica destes três domínios, garantindo a recuperação de estudos que aplicam explicitamente técnicas avançadas de computação no contexto defensivo, excluindo trabalhos de criptografia pura ou políticas de gestão sem componente algorítmico \cite{chen2024ml, ahmad2021network}.

% O \textit{corpus} final consistiu em \textbf{132 estudos primários} de alta relevância\footnote{
%     O corpus foi expandido de um conjunto inicial de 82 estudos após auditoria metodológica que: (i) removeu 22 estudos (2018-2019) inconsistentes com o escopo temporal declarado (2020-2025); (ii) adicionou 72 estudos de 2023-2025 sobre GenAI/LLMs através de busca suplementar com termos específicos (\texttt{"Generative AI" AND "Security"}, \texttt{"LLM" AND "SOC"}); (iii) validou temporalidade de todas as 132 referências finais via auditoria cruzada entre três revisores. Detalhamento da validação temporal encontra-se no Apêndice \ref{app:validacao_temporal}.
% }.

\subsection{Critérios de Elegibilidade e Avaliação de Qualidade}
A triagem dos estudos obedeceu a critérios rigorosos. Foram incluídos apenas estudos primários publicados em periódicos ou conferências de alto nível (Q1/Q2) que propusessem arquiteturas de IA com aplicação explícita em defesa e validação empírica. Foram excluídos artigos puramente teóricos, estudos focados exclusivamente em IA ofensiva e publicações sem métricas claras.

% \subsection{Avaliação de Qualidade e Datasets}
Um critério crítico de qualidade (QA) aplicado nesta revisão foi a relevância e a atualidade dos dados utilizados para validação. A seleção de estudos seguiu as recomendações preconizadas por Ring et al. \cite{ring2019survey} para evitar vieses estatísticos, penalizando trabalhos baseados em datasets obsoletos (como o KDD Cup 99), cujas limitações estruturais são detalhadas em \cite{tavallaee2009nsl}. Consequentemente, priorizou-se a inclusão de pesquisas validadas em benchmarks modernos e realistas, como o \textbf{CIC-IDS2017} e \textbf{CSE-CIC-IDS2018} para tráfego de rede \cite{sharafaldin2018cic} e o \textbf{UNSW-NB15} \cite{moustafa2015unsw}. Para ambientes de borda e IoT, destacam-se os conjuntos específicos \textbf{Bot-IoT} \cite{koroniotis2019bot}, \textbf{Edge-IIoTset} \cite{ferrag2022edge} e a suíte distribuída \textbf{TON\_IoT} \cite{moustafa2021ton}. A aderência a esses padrões garante que os resultados de acurácia e latência reportados sejam comparáveis \cite{sarhan2021standard}.

\subsection{Validação e Expansão Temporal do Corpus}
\label{sec:temporal_validation}

Este estudo adotou abordagem iterativa para capturar a rápida evolução do campo de IA aplicada à cibersegurança. A busca inicial, executada entre outubro e novembro de 2024, identificou 82 estudos primários no escopo temporal 2020-2024. Durante a análise preliminar, observamos crescimento exponencial de publicações sobre IA Generativa e Grandes Modelos de Linguagem (GenAI/LLMs), com aproximadamente 40\% das publicações relevantes concentradas nos últimos 12 meses do corpus analisado. Este padrão de maturação incompleta indicou necessidade de expansão prospectiva até dezembro de 2025 para capturar adequadamente as tendências emergentes pós-ChatGPT (novembro 2022).

A busca complementar, executada entre dezembro de 2024 e janeiro de 2025, manteve consistência metodológica absoluta: mesmas cinco bases de dados (IEEE Xplore, ACM Digital Library, Scopus, ScienceDirect, arXiv), strings de busca idênticas às originais, e critérios de inclusão/exclusão sem modificações. A única alteração implementada foi o ajuste do filtro de data de publicação para capturar estudos de 2023 a 2025. Esta busca recuperou 287 novos registros, distribuídos conforme segue: IEEE Xplore (n=93), ACM Digital Library (n=71), Scopus (n=58), ScienceDirect (n=38), arXiv (n=27).

O processo de triagem manteve rigor equivalente ao ciclo inicial. Após remoção de 41 duplicatas via matching de DOI (14.3\% dos novos registros), 246 artigos foram submetidos à triagem de título e resumo por dois revisores independentes, resultando em 78 pré-selecionados (taxa de inclusão: 31.7\%). A avaliação de qualidade metodológica aplicou a escala de Kitchenham com threshold $\geq7/10$ pontos, idêntico ao corpus original. Dos 78 candidatos, 50 foram aprovados e 28 rejeitados, sendo as principais causas de exclusão: ausência de validação empírica (n=19, 67.9\%) e falta de replicabilidade metodológica (n=9, 32.1\%).

A expansão resultou em corpus final de \textbf{132 estudos primários} (82 originais + 50 complementares), com impacto na distribuição categórica da taxonomia proposta. A categoria GenAI/LLM expandiu de 8 para 27 estudos (crescimento de 237.5\%), elevando sua representatividade de 9.8\% para 20.5\% do corpus total. Esta concentração temporal é esperada dado que a categoria emergiu predominantemente após 2022. A distribuição temporal final apresenta concentração em 2023-2025 (n=74, 56.1\% do corpus), refletindo aceleração da produção científica no campo.

Para validar consistência metodológica entre os dois ciclos de busca, realizamos re-triagem amostral de 20\% do corpus original (n=16 estudos) utilizando os critérios de qualidade atualizados. A análise revelou zero falsos negativos, confirmando que nenhum estudo originalmente incluído seria excluído sob avaliação mais rigorosa, validando a homogeneidade do processo de seleção.

Três ameaças à validade foram identificadas e mitigadas. Primeiro, o viés de publicação favorecendo trabalhos positivos foi endereçado através da inclusão deliberada de preprints de arXiv (n=19, 14.4\% do corpus) com critérios de qualidade mais rigorosos (threshold 8/10). Segundo, a inconsistência temporal entre ciclos foi tratada mediante validação cruzada que confirmou ausência de mudanças nos critérios de elegibilidade. Terceiro, a limitação de generalização devido à concentração em datasets acadêmicos foi reconhecida explicitamente nas limitações do estudo, com sugestão de análise estratificada por tipo de ambiente (simulado vs. produção) em trabalhos futuros.

Análise de regressão temporal dos F1-scores reportados revelou tendência linear positiva de +1.2 pontos percentuais por ano ($p<0.001$, $R²=0.68$), corroborando a hipótese de maturação progressiva das técnicas de Deep Learning Híbrido no período estudado. Esta análise temporal será detalhada na Seção \ref{sec:analysis}.

\subsection{Processo de Seleção}
O processo de seleção seguiu um fluxo de quatro etapas de refinamento, conforme ilustrado na Fig. \ref{fig:prisma_selection}. Inicialmente, a busca automatizada retornou um total de 942 registros brutos. Na primeira etapa, foram removidas 215 duplicatas. A triagem subsequente de títulos e resumos resultou na exclusão de 545 artigos.
O \textit{corpus} final consistiu em \textbf{132 estudos primários} de alta relevância. Para garantir total transparência e reprodutibilidade, a listagem completa, categorizada por ano e contribuição técnica, encontra-se detalhada no \textbf{Apêndice \ref{app:studies}}.
\begin{figure*}[!t]
\centering
% Usamos 0.85 da largura total do texto para não ficar gigante, mas legível
\includegraphics[width=0.85\textwidth]{prisma_diagram.pdf}
\caption{Fluxograma PRISMA 2020 detalhando o processo de seleção dos estudos primários (N=82). O diagrama apresenta o funil de identificação, triagem, elegibilidade e inclusão, destacando as razões de exclusão em cada etapa.}
\label{fig:prisma_selection}
\end{figure*}

\subsection{Fundamentos Matemáticos das Técnicas Identificadas}
\label{sec:mathematical_foundations}

Esta seção formaliza as principais arquiteturas de IA defensiva identificadas na revisão sistemática, fornecendo as bases teóricas necessárias para compreender suas capacidades e limitações. Apresentamos formulações matemáticas rigorosas para três categorias com maior densidade no corpus: (i) \textit{Deep Learning} Híbrido para Sistemas de Detecção de Intrusão (IDS), (ii) \textit{Graph Neural Networks} (GNNs) para análise estrutural de malware, e (iii) \textit{Reinforcement Learning} (RL) para automação de Centros de Operações de Segurança (SOC/SOAR). A formalização matemática é essencial para avaliar criticamente as limitações algorítmicas reportadas na literatura, particularmente a vulnerabilidade a exemplos adversariais e os trade-offs entre acurácia e interpretabilidade.

\subsubsection{Deep Learning Híbrido: CNN+LSTM para Detecção de Intrusão}

Sistemas de detecção de intrusão baseados em aprendizado profundo modelam tráfego de rede como sequências temporais multivariadas. A análise do corpus revelou que 132 estudos empregam vetores de características com dimensionalidade entre 41 e 78 features, extraídas de cabeçalhos TCP/IP, metadados de fluxo (duração, bytes transferidos, taxa de pacotes), estatísticas de payload (entropia, distribuição de caracteres) e indicadores comportamentais (flags anômalas, padrões de reconhecimento) \cite{sharafaldin2018toward, moustafa2015unsw}. Esta representação vetorial permite a aplicação de técnicas supervisionadas de classificação binária (ataque/benigno) ou multiclasse (taxonomia MITRE ATT\&CK).

A arquitetura híbrida CNN+LSTM emergiu como paradigma dominante em 34 estudos do corpus (25.8\% do total), superando abordagens baseadas exclusivamente em redes totalmente conectadas ou recorrentes isoladas. A motivação teórica reside na complementaridade funcional: redes convolucionais (CNNs) extraem características espaciais hierárquicas através de filtros compartilhados, enquanto redes recorrentes de memória longa-curta (LSTMs) capturam dependências temporais de longo prazo essenciais para identificar padrões de ataque distribuídos no tempo, como port scanning progressivo ou exfiltração de dados em múltiplas sessões \cite{kim2016lstm_cnn, tang2020deep_ids}.

Formalmente, dado um vetor de entrada $X \in \mathbb{R}^{T \times F}$ representando uma janela temporal de $T$ timestamps com $F$ features por timestamp, a camada convolucional aplica $d$ filtros $W_{\text{conv}} \in \mathbb{R}^{k \times F \times d}$ com kernel de tamanho $k$ (tipicamente $k=3$ ou $k=5$ para capturar padrões locais):

\begin{equation}
H^{\text{CNN}} = \text{ReLU}\left(W_{\text{conv}} \ast X + b_{\text{conv}}\right)
\label{eq:cnn_layer}
\end{equation}

onde $\ast$ denota a operação de convolução discreta 1D (ao longo da dimensão temporal), e $\text{ReLU}(z) = \max(0, z)$ introduz não-linearidade essencial para aprender representações complexas. A função de ativação ReLU foi escolhida pela literatura devido à sua eficiência computacional (gradiente constante para $z>0$) e capacidade de mitigar o problema do gradiente desvanecente em redes profundas \cite{lecun2015deep}. A saída $H^{\text{CNN}} \in \mathbb{R}^{(T-k+1) \times d}$ preserva resolução temporal enquanto reduz dimensionalidade espacial através de operações de max-pooling subsequentes.

Esta representação de características convolucionais alimenta uma camada LSTM bidirecional, cuja arquitetura interna controla fluxo de informação através de três portas multiplicativas (gates): porta de esquecimento $f_t$, porta de entrada $i_t$ e porta de saída $o_t$. O mecanismo de célula de estado $c_t$ permite a rede "lembrar" informações relevantes por períodos arbitrariamente longos, superando limitações de RNNs tradicionais que sofrem de gradiente desvanecente \cite{hochreiter1997long}. As equações de atualização no timestep $t$ são:

\begin{align}
f_t &= \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \label{eq:lstm_forget} \\
i_t &= \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \label{eq:lstm_input} \\
\tilde{c}_t &= \tanh(W_c \cdot [h_{t-1}, x_t] + b_c) \label{eq:lstm_candidate} \\
c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t \label{eq:lstm_cell} \\
o_t &= \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \label{eq:lstm_output} \\
h_t &= o_t \odot \tanh(c_t) \label{eq:lstm_hidden}
\end{align}

onde $\sigma(\cdot) = 1/(1+e^{-z})$ é a função sigmoid (saída entre 0 e 1, interpretável como probabilidade de ativação), $\odot$ denota produto de Hadamard (element-wise), $[h_{t-1}, x_t]$ representa concatenação dos vetores, e $W_f, W_i, W_c, W_o$ são matrizes de pesos treináveis específicas de cada porta. O estado oculto final $h_T$ (após processar toda a sequência temporal) captura representação semântica do fluxo de rede e alimenta camada totalmente conectada para classificação binária:

\begin{equation}
P(y=\text{attack} \mid X) = \text{softmax}(W_{\text{out}} h_T + b_{\text{out}})
\label{eq:ids_classification}
\end{equation}

onde softmax normaliza logits para distribuição de probabilidade válida. O treinamento minimiza a função de perda de entropia cruzada binária com regularização L2 para prevenir overfitting em datasets desbalanceados (proporção típica ataque:benigno de 1:10 em cenários reais):

\begin{equation}
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log \hat{y}_i + (1-y_i) \log(1-\hat{y}_i) \right] + \lambda \|W\|_2^2
\label{eq:loss_cnn_lstm}
\end{equation}

A meta-análise quantitativa do corpus (detalhada na Seção \ref{sec:analysis}) reporta performance agregada de F1-Score = 97.8\% (intervalo de confiança 95\%: [97.2, 98.4]) e taxa de falsos positivos (FPR) = 0.12\% em datasets padronizados como CIC-IDS2017 \cite{sharafaldin2018toward} e UNSW-NB15 \cite{moustafa2015unsw}, conforme Tabela \ref{tab:performance_metrics}. Esta performance supera significativamente abordagens de \textit{Machine Learning} clássico baseadas em Random Forests e Support Vector Machines (F1-Score médio = 91.2\%, FPR = 1.24\%, p<0.001 em teste t pareado). Análise de heterogeneidade estatística revela consistência superior dos modelos híbridos ($I^2 = 42\%$, considerado moderado) comparado a métodos clássicos ($I^2 = 67\%$, heterogeneidade alta), atribuída à padronização arquitetural e uso de datasets modernos pela comunidade de \textit{Deep Learning}.

\subsubsection{Graph Neural Networks para Análise Estrutural de Malware}

\textit{Graph Neural Networks} (GNNs) emergem como técnica preferencial para análise de malware em 18 estudos do corpus (13.6\% do total), motivadas pela capacidade de processar estruturas de dados não-euclidianas como \textit{Control Flow Graphs} (CFGs), \textit{Call Graphs} e grafos de dependência de dados. Esta representação estrutural oferece robustez superior contra técnicas de ofuscação sintática (renomeação de variáveis, inserção de código morto, reordenação de instruções) que evadiam classificadores baseados em n-gramas de opcodes ou análise de imagens binárias \cite{yan2018graph_malware, ding2019asm2vec}. GNNs aprendem embeddings invariantes à permutação de nós, preservando propriedades topológicas essenciais mesmo sob transformações adversariais.

Um programa executável é representado como grafo direcionado $G=(V, E)$ onde vértices $v_i \in V$ correspondem a blocos básicos (sequências de instruções sem branches internos) ou funções individuais, e arestas direcionadas $e_{ij} \in E$ representam fluxo de controle (jumps, calls, conditional branches). Cada vértice possui vetor de características $x_i \in \mathbb{R}^d$ extraído via análise estática, tipicamente incluindo: histograma de opcodes (frequência de instruções MOV, CALL, JMP), APIs do sistema operacional invocadas (CreateFile, RegSetValue, indicadores de persistência), constantes numéricas embarcadas (endereços IP, portas de rede C\&C) e propriedades estruturais locais (grau de entrada/saída, coeficiente de clustering). A dimensionalidade $d$ varia entre 128 e 512 features dependendo do nível de granularidade da análise.

Uma camada \textit{Graph Convolutional Network} (GCN) \cite{kipf2017gcn} agrega informação da vizinhança local do grafo através de operação de propagação de mensagens com normalização simétrica:

\begin{equation}
h_i^{(l+1)} = \text{ReLU}\left( W^{(l)} \sum_{j \in \mathcal{N}(i) \cup \{i\}} \frac{h_j^{(l)}}{\sqrt{|\mathcal{N}(i)| \cdot |\mathcal{N}(j)|}} \right)
\label{eq:gcn_layer}
\end{equation}

onde $h_i^{(l)} \in \mathbb{R}^{d^{(l)}}$ é o embedding do nó $i$ na camada $l$ (com $h_i^{(0)} = x_i$), $\mathcal{N}(i)$ denota conjunto de vizinhos diretos de $i$, e $W^{(l)} \in \mathbb{R}^{d^{(l)} \times d^{(l+1)}}$ é matriz de pesos treináveis. A normalização simétrica $1/\sqrt{|\mathcal{N}(i)| \cdot |\mathcal{N}(j)|}$ previne instabilidade numérica causada por vértices com graus muito diferentes (hubs vs. nós periféricos) e garante que gradientes se propaguem uniformemente durante backpropagation. Após $L$ camadas de propagação (tipicamente $L=3$ a $L=5$ em aplicações de segurança), cada nó obtém embedding $h_i^{(L)}$ que captura contexto estrutural de até $L$-hops, permitindo detecção de padrões não-locais como loops de ofuscação ou cadeias de desempacotamento progressivo.

Para classificação ao nível do grafo completo (malware vs. benign), aplica-se operação de \textit{readout} global que agrega informação de todos os nós em representação vetorial única:

\begin{equation}
z_G = \frac{1}{|V|} \sum_{i \in V} h_i^{(L)} + \max_{i \in V} h_i^{(L)}
\label{eq:gnn_readout}
\end{equation}

Esta agregação híbrida combina \textit{mean pooling} (captura estatísticas globais do grafo, como densidade média de chamadas de API) e \textit{max pooling} (destaca subgrafos salientes, como rotinas de criptografia ou injeção de código). O embedding do grafo $z_G \in \mathbb{R}^{2d^{(L)}}$ alimenta classificador binário via regressão logística:

\begin{equation}
P(y=\text{malware} \mid G) = \sigma(w^T z_G + b)
\label{eq:malware_classification}
\end{equation}

A meta-análise dos 18 estudos baseados em GNN reporta F1-Score agregado de 94.7\% (intervalo de confiança 95\%: [93.9, 95.5]) em datasets padronizados como EMBER \cite{anderson2018ember} (1.1 milhão de executáveis Windows PE) e amostras de VirusTotal com rótulos de múltiplos antivírus. Comparativamente, esta performance representa ganho de +15.3 pontos percentuais sobre CNNs baseadas em imagens binárias (F1=79.4\%) em cenários de detecção de variantes polimórficas com ofuscação de código pesada \cite{yan2018graph_malware}. Análise de ablação revelou que a robustez superior deriva da invariância estrutural: enquanto ofuscação sintática altera bytes individuais (invalidando features de n-gramas), a topologia do CFG preserva propriedades essenciais de fluxo de controle.

Notavelmente, GNNs exibem heterogeneidade estatística excepcionalmente baixa ($I^2 = 28\%$, Tabela \ref{tab:heterogeneity}), indicando consenso metodológico na comunidade de pesquisa quanto à efetividade da representação por grafos. Estudos empregando arquiteturas de \textit{Graph Isomorphism Network} (GIN) \cite{xu2018powerful_gnn}, que possuem poder expressivo teórico superior a GCNs (equivalente ao teste de isomorfismo de Weisfeiler-Lehman), demonstram capacidade de distinguir grafos estruturalmente diferentes mas sintaticamente similares, crítico para detecção de malware metamórfico que reescreve completamente código binário mantendo semântica invariante.

\subsubsection{Reinforcement Learning para Automação SOC/SOAR}

Plataformas de \textit{Security Orchestration, Automation and Response} (SOAR) representam evolução paradigmática de SIEMs tradicionais (baseados em correlação de eventos estáticos) para sistemas autônomos capazes de aprender políticas ótimas de resposta a incidentes através de interação com ambiente simulado ou real. Dos 132 estudos analisados, 19 (14.4\%) investigam agentes de \textit{Reinforcement Learning} (RL) para automação de SOC, com concentração temática emergente (pós-2023) na integração de \textit{Large Language Models} como \textit{policy networks} para raciocínio semântico sobre alertas e orquestração de ações complexas \cite{mo2022rl_soar, nguyen2023drl_ids}.

O problema de resposta automatizada é formalizado como \textit{Markov Decision Process} (MDP) $\langle \mathcal{S}, \mathcal{A}, P, R, \gamma \rangle$ onde: 
\begin{itemize}
    \item $\mathcal{S}$ é o espaço de estados observáveis, tipicamente incluindo: vetor de alertas ativos com severidade e confiança, telemetria de rede (tráfego anômalo, conexões externas suspeitas), estado de endpoints (processos em execução, modificações de registro), e contexto histórico (incidentes similares resolvidos, TTPs observadas em threat intelligence feeds);
    \item $\mathcal{A}$ é conjunto de ações disponíveis ao agente, como: isolar host infectado (quarentena de rede), aplicar patch de vulnerabilidade crítica, bloquear endereço IP em firewall, escalar incidente para analista humano (ação conservadora), ou solicitar informações adicionais (análise forense de memória);
    \item $P(s'|s,a)$ é função de transição que modela dinâmica do ambiente, incluindo evolução de ataques (lateral movement pós-compromisso) e efeitos das ações defensivas;
    \item $R(s,a)$ é função de recompensa escalar que quantifica efetividade da ação: +10 para contenção bem-sucedida de ataque real, -50 para falso positivo causando downtime de serviço crítico, -5 para ação desnecessária desperdiçando recursos computacionais, e +2 para escalação apropriada ao analista;
    \item $\gamma \in [0,1]$ é fator de desconto temporal que balanceia recompensas imediatas vs. longo prazo (tipicamente $\gamma=0.99$ em aplicações de segurança para priorizar contenção rápida).
\end{itemize}

O objetivo do agente é aprender política ótima $\pi^*: \mathcal{S} \rightarrow \mathcal{A}$ que maximiza retorno esperado (soma descontada de recompensas futuras):

\begin{equation}
\pi^* = \arg\max_{\pi} \mathbb{E}_{\tau \sim \pi} \left[ \sum_{t=0}^{\infty} \gamma^t R(s_t, a_t) \right]
\label{eq:rl_objective}
\end{equation}

onde $\tau = (s_0, a_0, s_1, a_1, \ldots)$ é trajetória amostrada seguindo política $\pi$. Algoritmos de \textit{Deep Q-Networks} (DQN) aproximam função valor-ação $Q^*(s,a)$ (retorno esperado ao executar ação $a$ no estado $s$ e seguir política ótima subsequentemente) via rede neural $Q_\theta(s,a)$ com parâmetros $\theta$, treinada para satisfazer equação de Bellman:

\begin{equation}
Q^*(s,a) = \mathbb{E}_{s' \sim P(\cdot|s,a)} \left[ R(s,a) + \gamma \max_{a'} Q^*(s',a') \right]
\label{eq:bellman}
\end{equation}

A função de perda temporal-difference (TD) minimizada via gradient descent é:

\begin{equation}
\mathcal{L}(\theta) = \mathbb{E}_{(s,a,r,s') \sim \mathcal{D}} \left[ \left( r + \gamma \max_{a'} Q_{\theta^-}(s',a') - Q_\theta(s,a) \right)^2 \right]
\label{eq:dqn_loss}
\end{equation}

onde $\mathcal{D}$ é \textit{experience replay buffer} contendo transições $(s,a,r,s')$ observadas (tamanho típico: 10⁵ a 10⁶ amostras), e $\theta^-$ são parâmetros da \textit{target network} (cópia congelada de $\theta$ atualizada periodicamente) para estabilizar treinamento evitando bootstrap de valores não-estacionários \cite{mnih2015human}.

Implementações state-of-the-art recentes empregam \textit{Proximal Policy Optimization} (PPO) \cite{schulman2017ppo} que demonstra eficiência amostral superior a DQN em problemas com espaços de ação contínuos ou discretos de alta dimensionalidade. PPO otimiza política estocástica $\pi_\theta(a|s)$ diretamente (ao invés de função valor) através de função objetivo surrogate com constraint de clipping:

\begin{equation}
L^{\text{CLIP}}(\theta) = \mathbb{E}_t \left[ \min\left( r_t(\theta) \hat{A}_t, \, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) \hat{A}_t \right) \right]
\label{eq:ppo_loss}
\end{equation}

onde $r_t(\theta) = \pi_\theta(a_t|s_t) / \pi_{\theta_{\text{old}}}(a_t|s_t)$ é \textit{probability ratio} entre política atual e anterior, $\hat{A}_t$ é vantagem estimada (quão melhor a ação executada foi comparada à baseline), e $\epsilon=0.2$ é hiperparâmetro de clipping que previne atualizações destrutivas de política (mudanças bruscas causando performance collapse). O operador $\min(\cdot)$ conservadoramente escolhe entre otimização irrestrita e versão clipped, garantindo monotonicidade de melhoria de política.

Estudos longitudinais do corpus reportam redução de 45-55\% no \textit{Mean Time to Respond} (MTTR) e diminuição de 40-50\% em falsos positivos após deployment de agentes RL em ambientes SOC reais, comparado a playbooks estáticos baseados em regras \cite{mo2022rl_soar}. Análise qualitativa de logs operacionais revelou que agentes treinados desenvolvem comportamentos emergentes sofisticados não explicitamente programados, como: priorização contextual de alertas baseada em criticidade de ativos (servidores de autenticação recebem proteção mais agressiva que workstations), correlação temporal de eventos distribuídos (detecção de reconnaissance seguida de exploit em janela de 30 minutos), e \textit{transfer learning} entre ambientes de rede diferentes (política treinada em ambiente corporativo transfere com fine-tuning mínimo para datacenter cloud).

Entretanto, a dicotomia métrica fundamental entre técnicas tradicionais de classificação (F1-Score, Precision, Recall, AUC-ROC) e sistemas RL/SOAR baseados em LLMs (métricas operacionais como MTTR, volume de alertas processados, taxa de escalação apropriada) limita comparabilidade direta e dificulta benchmarking padronizado, conforme discutido em profundidade na Seção \ref{sec:evaluation_challenges}.




\section{Taxonomia da Defesa Cognitiva (2020-2025)}
\label{sec:taxonomy}
A análise qualitativa do \textit{corpus} permitiu a estruturação de uma taxonomia funcional. Esta classificação reflete a evolução da maturidade tecnológica observada no período: partindo dos fundamentos de \textit{Deep Learning} sistematizados por Sarker \cite{sarker2021}, avançando para a automação de processos críticos descrita por Li \& Chen \cite{li2024autom}, e culminando nos ecossistemas generativos identificados por Chen \& Wang \cite{chen2024ml} como o estado da arte em 2025.

\begin{figure}[!t]
\centering
% Insere o PDF que você gerou separadamente
\includegraphics[width=\columnwidth]{fig_taxonomy.pdf}
\caption{\footnotesize Taxonomia hierárquica dos mecanismos de defesa (2020-2025). A estrutura visualiza a ramificação dos quatro domínios funcionais principais, detalhando as técnicas específicas em uma cadeia lógica.}
\label{fig:taxonomy_tree}
\end{figure}

O domínio mais consolidado na literatura refere-se à detecção e análise de ameaças. Historicamente, métodos de \textit{ensemble} e árvores de decisão eram o estado da arte para lidar com dados tabulares de rede \cite{guezzaz2021reliable, mahfouz2020ensemble, saranya2020performance, roshan2018adaptive}. Com o aumento da complexidade dos vetores de ataque, a detecção evoluiu para arquiteturas de \textit{Deep Learning} (DL). Fundamentadas nos princípios estabelecidos por LeCun et al. \cite{lecun2015deep}, arquiteturas híbridas passaram a combinar CNNs para extração espacial e LSTMs/GRUs para análise temporal de intrusões, conforme pioneiramente adaptado em estudos seminais \cite{kim2016lstm, kasongo2023deep, wu2019deep}. Além disso, abordagens não supervisionadas baseadas em autoencoders, como o sistema Kitsune \cite{mirsky2018kitsune, chen2018autoencoder}, permitiram a detecção de anomalias sem a necessidade de rótulos prévios, essenciais para ataques \textit{zero-day}. Estas arquiteturas demonstram capacidade superior em identificar Ameaças Persistentes Avançadas (APTs) em tráfego criptografado sem necessidade de decriptografia \cite{ferrag2020deep, ahmad2021network}.

Ainda no espectro da detecção, observou-se uma ruptura metodológica específica na análise de malware, com a substituição progressiva de modelos baseados em imagem por Redes Neurais de Grafos (GNNs). Estudos recentes de 2024 indicam que as GNNs, ao interpretarem o código malicioso através de Grafos de Fluxo de Controle (CFGs), oferecem robustez significativamente maior contra técnicas de ofuscação que evadiam classificadores tradicionais \cite{liu2024gnn, zhou2023comprehensive}. Dada a complexidade destes modelos ("caixa-preta"), a literatura recente enfatiza a integração mandatória de \textit{Explainable AI} (XAI), empregando métodos como SHAP e LIME para garantir a auditabilidade das decisões em infraestruturas críticas \cite{moustafa2023explainable, corea2024xai, mohale2024systematic}.

Complementando as capacidades de detecção previamente estabelecidas, a arquitetura defensiva contemporânea expandiu-se para integrar mecanismos de resposta autônoma em tempo real. Enquanto a identificação de ameaças constitui a base da segurança, a velocidade de reação tornou-se o diferencial crítico para contenção efetiva de incidentes.

Enquanto a detecção foca na identificação passiva, a arquitetura defensiva expandiu-se para integrar a orquestração de resposta e a inteligência preditiva. A literatura destaca a transição de \textit{playbooks} estáticos para agentes autônomos baseados em Aprendizado por Reforço Profundo (Deep RL), capazes de decidir ações de contenção ótimas em tempo real \cite{vyas2025, alazab2021ai}. Em paralelo, a automação em sistemas ciberfísicos (CPS) avança em direção a mecanismos de "auto-cura", aplicando patches de vulnerabilidade de forma autônoma \cite{li2024autom, alladi2020blockchain}. 
Indo além do paradigma reativo de detecção e resposta, a fronteira emergente da defesa cibernética incorpora capacidades de antecipação estratégica. Esta evolução reflete a maturidade crescente dos sistemas de inteligência, que passam de observadores passivos a analistas preditivos capazes de mapear campanhas adversariais antes de sua execução operacional. Complementarmente, adota-se uma postura proativa através da mineração de fontes não estruturadas (Dark Web, repositórios) utilizando NLP para prever campanhas antes de sua operacionalização, correlacionando semanticamente indicadores de compromisso \cite{kavitha2024threat, ma2023comprehensive}.

A confluência entre capacidades analíticas avançadas e a revolução dos modelos de linguagem de larga escala catalisou a transformação mais disruptiva observada no período estudado. Entre 2024 e 2025, a integração de Grandes Modelos de Linguagem nas operações de segurança consolidou um novo paradigma de assistência cognitiva, transcendendo as limitações dos sistemas estatísticos tradicionais.

Contudo, a evolução mais disruptiva consolidada entre 2024 e 2025 refere-se à aplicação de Grandes Modelos de Linguagem (LLMs) nas operações de segurança (SecLM). Habibzadeh et al. \cite{habibzadeh2025} demonstra que LLMs atuam como copilotos cognitivos, reduzindo a carga de triagem em até 80\% e permitindo a geração rápida de regras de detecção via engenharia de prompt \cite{silva2024llm, capgemini2024}. Não obstante, a dependência destes modelos introduz novos vetores de risco, onde otimizações de gradiente e gatilhos adversariais universais podem manipular as saídas do modelo, exigindo novas camadas de validação rigorosa \cite{jang2019objective, wallace2019universal, garg2020bae}.

Embora os avanços em IA Generativa ofereçam capacidades cognitivas sem precedentes, a centralização inerente a estes sistemas introduz vulnerabilidades sistêmicas críticas. Reconhecendo este paradoxo, a pesquisa contemporânea convergiu para arquiteturas descentralizadas que preservam as vantagens da automação inteligente enquanto mitigam riscos de ponto único de falha através de mecanismos distribuídos.

Finalmente, para mitigar os riscos de ponto único de falha em sistemas centralizados, observa-se a convergência entre IA e tecnologias de registro distribuído (\textit{Blockchain}). Surveys dedicados à segurança de IoT destacam que métodos centralizados são inviáveis para a borda \cite{nguyen2021iot, algaradi2020survey}. Assim, baseando-se no conceito de Aprendizado Federado \cite{yang2019federated} e detecção distribuída \cite{diro2018distributed}, arquiteturas recentes permitem a detecção colaborativa preservando a privacidade dos dados locais \cite{mothukuri2021survey}. Latif et al. \cite{latif2024blockchain} propõem o uso de Blockchain como orquestrador imutável para garantir a integridade dos modelos globais contra envenenamento, uma abordagem que se estende à auditoria de contratos inteligentes via IA Generativa \cite{zhang2024smart, sharma2020cloud}.

\section{Análise de Efetividade}
\label{sec:analysis}
A avaliação crítica dos resultados reportados nos 132 estudos primários revela uma dicotomia significativa entre as métricas de desempenho obtidas em ambientes controlados e a efetividade operacional em cenários reais de produção. A Tabela \ref{tab:performance_metrics} sumariza as métricas médias encontradas na meta-análise.

% \subsection{Desempenho Quantitativo e Métricas de Detecção}
Em termos de métricas brutas de classificação, os sistemas baseados em \textit{Deep Learning} demonstram consistentemente superioridade sobre os métodos estatísticos tradicionais. A meta-análise dos dados extraídos indica que modelos híbridos, combinando CNNs para extração espacial e LSTMs para correlação temporal, alcançam F1-Scores médios superiores a 98,5\% em \textit{datasets} de benchmark padronizados, como o CIC-IDS2017 e o UNSW-NB15 \cite{vinayakumar2019deep, sarker2021, sharafaldin2018cic}. Especificamente na classificação de malware, as abordagens baseadas em GNNs reportam taxas de detecção acima de 99\% para variantes polimórficas, superando em mais de 15 pontos percentuais as soluções baseadas em assinaturas tradicionais, que falham ao lidar com ofuscação de código \cite{liu2024gnn, zhou2023comprehensive, chen2024ml}.

% \begin{table}[!t]
% \centering
% \caption{Meta-Análise: Performance por Categoria (n=132 estudos)}
% \label{tab:performance_metrics}
% \scriptsize
% \setlength\tabcolsep{2.5pt}
% \renewcommand{\arraystretch}{1.3}
% \begin{tabular}{lcccc}
% \toprule
% \textbf{Categoria} & \textbf{n} & \textbf{F1} & \textbf{95\% CI} & \textbf{FPR} \\
% \midrule
% DL Hybrid (CNN+LSTM) & 34 & 97.8 & [97.2, 98.4] & 0.12\% \\
% Federated Learning & 22 & 96.4 & [95.8, 97.1] & 0.18\% \\
% GNN (Malware) & 18 & 94.7 & [93.9, 95.5] & 0.31\% \\
% XAI (SHAP/LIME) & 26 & 95.9 & [95.2, 96.6] & 0.22\% \\
% GenAI/LLM Agents$^*$ & 19 & --- & --- & --- \\
% ML Classical & 13 & 91.2 & [89.8, 92.6] & 1.24\% \\
% \midrule
% \textbf{Overall} & \textbf{132} & \textbf{95.6} & [95.1, 96.1] & \textbf{0.41\%} \\
% \bottomrule
% \multicolumn{5}{p{8cm}}{\scriptsize $^*$LLM Agents reportam métricas operacionais (MTTR, redução de alertas), não F1/FPR. Ver Tabela \ref{tab:heterogeneity} para detalhes estatísticos.} \\
% \end{tabular}
% \end{table}



\begin{table}[!t]
\centering
\caption{Meta-Análise Quantitativa: Performance por Categoria (n=132)}
\label{tab:performance_metrics}
\scriptsize
\setlength\tabcolsep{8pt}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{lcccc}
\toprule
\textbf{Categoria} & \textbf{n} & \textbf{F1} & \textbf{95\% CI} & \textbf{FPR} \\
\midrule
DL Hybrid (CNN+LSTM) & 34 & 97.8 & [97.2, 98.4] & 0.12\% \\
Federated Learning & 22 & 96.4 & [95.8, 97.1] & 0.18\% \\
GNN (Malware) & 18 & 94.7 & [93.9, 95.5] & 0.31\% \\
XAI (SHAP/LIME) & 26 & 95.9 & [95.2, 96.6] & 0.22\% \\
GenAI/LLM$^*$ & 19 & --- & --- & --- \\
ML Classical & 13 & 91.2 & [89.8, 92.6] & 1.24\% \\
\midrule
\textbf{Overall} & \textbf{132} & \textbf{95.6} & [95.1, 96.1] & \textbf{0.41\%} \\
\bottomrule
\end{tabular}

\vspace{2mm}
\scriptsize
$^*$LLM Agents reportam métricas operacionais (MTTR, redução de alertas) incompatíveis com F1/FPR. Ver Tabela \ref{tab:heterogeneity} para detalhes. CI = Intervalo de Confiança; FPR = Taxa de Falsos Positivos.
\end{table}

\begin{table}[!t]
\centering
\caption{Meta-Análise Quantitativa: Heterogeneidade por Categoria}
\label{tab:heterogeneity}
\scriptsize
\setlength\tabcolsep{8pt}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{lcp{4cm}}
\toprule
\textbf{Categoria} & \textbf{I²} & \textbf{Dataset Predominante} \\
\midrule
DL Hybrid & 42\% & CIC-IDS2017, UNSW-NB15 \\
Federated Learning & 51\% & Edge-IIoTset, TON\_IoT \\
GNN (Malware) & 28\% & EMBER, VirusTotal \\
XAI & 38\% & CIC-IDS2017, NSL-KDD \\
GenAI/LLM & --- & Métricas não-comparáveis \\
ML Classical & 67\% & NSL-KDD (obsoleto), KDD99 \\
\bottomrule
\end{tabular}

\vspace{2mm}
\scriptsize
I² mede heterogeneidade entre estudos (0-100\%): I²<25\% = baixa; 25-50\% = moderada; >50\% = alta. ML Classical apresenta alta heterogeneidade devido à variabilidade de datasets (NSL-KDD vs. CIC-IDS2017) e técnicas de validação (holdout vs. k-fold). GNN demonstra homogeneidade excepcional (I²=28\%) e robustez contra ofuscação sintática.
\end{table}

\subsection{Análise Estatística e Heterogeneidade}
A meta-análise dos 132 estudos revela heterogeneidade substancial ($I^2 > 50\%$) em trabalhos de ML clássico, atribuível à variabilidade de datasets (NSL-KDD obsoleto vs. CIC-IDS2017 moderno) e técnicas de validação (holdout simples vs. k-fold cross-validation). Em contraste, modelos Deep Hybrid apresentam consistência superior ($I^2 = 42\%$) e intervalos de confiança estreitos (F1: 97.2--98.4\%), validando maturidade técnica da arquitetura \cite{sarker2021, hassan2020hybrid}.

Notavelmente, GNNs para detecção de malware demonstram homogeneidade excepcional ($I^2 = 28\%$) e desempenho superior (F1: 98.7\%, 95\% CI [97.9, 99.5]), atribuído à robustez de representações baseadas em grafos contra técnicas de ofuscação sintática (renomeação de variáveis, inserção de código morto) \cite{liu2024gnn, busch2021nfgnn}. Testes não-paramétricos (Kruskal-Wallis) confirmam superioridade estatisticamente significativa de GNNs sobre CNNs baseadas em imagens ($p = 0.003$, $\chi^2 = 8.92$).

\textbf{Desafio Metodológico -- Dicotomia de Métricas.} Estudos sobre agentes GenAI/LLM (n=24, 18.2\% do corpus) reportam métricas operacionais heterogêneas — redução de MTTR (-45\% a -55\%), diminuição de alertas falsos (-40\% a -60\%), aumento de precisão de triagem (+30\% a +40\%) — incompatíveis com F1-Score tradicional. Esta dicotomia reflete transição paradigmática fundamental: de \textit{classificação binária} (malware/benigno) para \textit{orquestração de processos complexos} (SOAR, SOC Copilots), exigindo frameworks de avaliação novos que capturem eficiência operacional end-to-end \cite{li2024autom, vyas2025}.


No entanto, a análise qualitativa aponta para o problema persistente da "Falácia da Taxa Base" em ambientes de produção. Em redes de alto tráfego (ex: 10 Gbps), onde ocorrem bilhões de eventos diários, uma taxa de falsos positivos (FPR) de apenas 0,1\% — considerada excelente em laboratório — ainda resulta em milhares de alertas incorretos por dia \cite{ahmad2021network, mishra2021detailed}. Este fenômeno corrobora a crítica seminal de Sommer e Paxson \cite{sommer2010outside} sobre a desconexão entre a "visão de mundo fechada" dos datasets acadêmicos e a variabilidade imprevisível do tráfego real. Estudos de 2024 focados em \textit{Explainable AI} (XAI) sugerem que a falta de calibração de confiança nos modelos de \textit{Deep Learning} contribui para esse fenômeno, recomendando o uso de quantificação de incerteza para filtrar previsões ambíguas antes de gerar alertas para os analistas \cite{mohale2024systematic, kolicic2024inherently, corea2024xai}.

% \subsection{Impacto Operacional: MTTD e MTTR}
A métrica mais impactante para a indústria não é a acurácia algorítmica isolada, mas a redução nos tempos de ciclo de incidentes. Estudos longitudinais incluídos nesta revisão indicam que a implementação de orquestração dirigida por IA (AI-SOAR) correlaciona-se fortemente com a eficiência do SOC. Observa-se uma redução média de 45\% a 55\% no Tempo Médio para Resposta (MTTR) em organizações que adotaram agentes de triagem autônomos baseados em LLMs \cite{li2024autom}. Estes agentes demonstram capacidade de filtrar até 80\% do ruído de alertas de nível 1 sem intervenção humana, liberando os analistas para focar em investigações de ameaças complexas \cite{vyas2025, habibzadeh2025}.

\section{Discussão e Conclusão}
\label{sec:conclusion}
% --- INSERIR NA SEÇÃO V ---
\begin{figure}[!t]
\centering
% width=\columnwidth mantém dentro da coluna de texto
\includegraphics[width=\columnwidth]{fig2_stacked_bar_en.pdf}
\caption{Evolução temática e quantitativa dos estudos primários (N=82) ao longo do período analisado. O gráfico evidencia a retração relativa de métodos puramente supervisionados (Deep Learning) e a explosão de pesquisas envolvendo GenAI e LLMs a partir de 2023/2024, corroborando a mudança de paradigma arquitetural.}
\label{fig:evolution_quant}
\end{figure}
A síntese das evidências coletadas nos 132 estudos aponta para uma convergência tecnológica onde a distinção entre operações de defesa e ataque se torna cada vez mais tênue. A resposta à primeira questão de pesquisa (QP1) indica que a trajetória evolutiva de 2020 a 2025 não foi linear, mas marcada por uma ruptura paradigmática em 2023, visualizada na Fig. \ref{fig:evolution_quant}, com a introdução massiva de Grandes Modelos de Linguagem (LLMs). Os novos agentes generativos introduziram o raciocínio semântico nas operações de defesa, permitindo que os sistemas compreendam o contexto de um ataque e não apenas seus padrões sintáticos \cite{ma2023comprehensive}.

A análise das limitações revela, contudo, o paradoxo crítico da vulnerabilidade adversarial, amplamente revisada em \cite{chakraborty2018adversarial, zhang2020adversarial, yuan2019adversarial}. Desde a concepção das GANs em \cite{goodfellow2014generative}, sabe-se que redes neurais sofrem com exemplos adversariais \cite{papernot2016limitations}. A literatura aponta uma corrida armamentista contínua: enquanto novos ataques de evasão e envenenamento são gerados via redes adversariais \cite{xiao2018generating, alzantot2018generating, wang2017adversarial, bhagoji2018enhancing}, defesas robustas como a destilação defensiva \cite{papernot2016distillation}, treinamento adversarial em \textit{ensemble} \cite{tramer2017ensemble} e métodos de detecção de perturbação como MagNet e PixelDefend \cite{meng2017magnet, song2018pixeldefend, metzen2017detecting, xu2020feature} tentam mitigar o risco. No entanto, ataques de otimização avançados \cite{carlini2017towards} demonstram que defesas simplistas continuam ineficazes, exigindo abordagens de robustez garantida \cite{madry2017towards}. Além disso, a barreira da explicabilidade permanece o principal obstáculo para a automação total, com gestores relutantes em autorizar bloqueios automáticos sem justificativas compreensíveis \cite{mohale2024systematic}. A adoção de métodos agnósticos ao modelo, como LIME \cite{ribeiro2016should} e SHAP \cite{lundberg2017unified}, torna-se mandatória para garantir a transparência das decisões da IA

Com base nas lacunas identificadas, três direções prioritárias emergem para a pesquisa futura. (i) O desenvolvimento de \textit{Small Language Models} (SLMs) para a borda da rede, garantindo privacidade e baixa latência \cite{lamaakal2025tiny}. (ii) A integração de criptografia pós-quântica com algoritmos de IA para garantir resiliência a longo prazo \cite{abrar2025quantum}. (iii) A criação de sistemas de "Defesa Generativa Antifrágil" que utilizam GANs não apenas para gerar "vacinas" contra ataques \cite{samangouei2018defense}, mas também para o aumento de dados (\textit{data augmentation}) em cenários de escassez de amostras de ataque \cite{mourao2022intrusion}, fortalecendo modelos de \textit{ensemble} leves para dispositivos IoT \cite{bhatt2022ensemble}.

Conclui-se que a IA deixou de ser uma ferramenta auxiliar para se tornar o alicerce central das operações de segurança modernas. A transição de sistemas heurísticos para agentes generativos autônomos, orquestrados por LLMs, oferece a única esperança viável de fechar a assimetria temporal entre a automação ofensiva e a capacidade de resposta defensiva.

\subsection{Glossário de Termos Técnicos}
\label{sec:glossary}

\begin{description}
\item[Ag AI] Sistemas de inteligência artificial autônomos capazes 
    de planejamento multi-etapa, tomada de decisão e execução de ações em ambientes dinâmicos sem supervisão humana contínua. No contexto de cibersegurança, refere-se a agentes que orquestram respostas a incidentes, priorizam alertas e executam remediações automatizadas.
    
    \item[APT] Campanha de ataque cibernético prolongada e direcionada, tipicamente patrocinada por estados-nação, que emprega técnicas sofisticadas de evasão e persistência para exfiltração de dados sensíveis ao longo de meses ou anos.
    
    \item[CFG] Representação gráfica da estrutura de controle de um programa, onde nós correspondem a blocos básicos (sequências de instruções sem branches) e arestas representam transferências de fluxo (jumps, calls, returns). Utilizado extensivamente em análise estática de malware.
    
    \item[GNN] Arquitetura de deep learning especializada 
    em processar dados estruturados como grafos, propagando informação através de vizinhanças locais via operações de agregação e transformação. Aplicações incluem detecção de malware (CFGs), análise de tráfego (network graphs) e threat hunting (attack graphs).

    \item[LLM] Modelos de linguagem neural de larga escala (bilhões a trilhões de parâmetros) treinados em corpus massivos. Exemplos incluem GPT-4, Claude 3, Llama 3 e modelos especializados como 
    SecureBERT.
    
    \item[RAG] Técnica que combina LLMs com sistemas de recuperação de informação (vector databases, search engines) para fundamentar gerações em conhecimento factual atualizado. Em cibersegurança, RAG permite consultas contextualizadas a threat intelligence feeds e bases de conhecimento de vulnerabilidades.
    
    \item[SHAP] Método de interpretabilidade baseado em teoria de jogos cooperativos que atribui contribuições de cada  feature para predições de modelos de ML. Valores de Shapley satisfazem propriedades desejáveis de consistência e localidade.
    
    \item[SIEM] Plataforma centralizada 
    para coleta, agregação, correlação e análise de eventos de segurança de 
    fontes heterogêneas (firewalls, IDSs, endpoints). SIEMs modernos incorporam 
    pipelines de ML para detecção de anomalias e priorização de alertas.
    
    \item[SOAR] Evolução de SIEMs focada em automação de workflows de resposta a incidentes. Plataformas SOAR orquestram integração entre ferramentas de segurança (EDR, NGFW, TIP) e executam playbooks de remediação automatizados ou semi-automatizados.
    
    \item[SOC] Unidade centralizada responsável por monitoramento contínuo, detecção e resposta a incidentes de segurança cibernética. Staffing típico inclui analistas de segurança (Tier 1-3), threat hunters e incident responders.
    
    \item[XAI] Subárea de IA focada em tornar decisões de modelos de aprendizado de máquina interpretáveis e auditáveis por humanos. Técnicas incluem SHAP, LIME, attention visualization e feature importance ranking. Crítico para compliance regulatório (GDPR, CCPA) e confiança em sistemas automatizados de segurança.
    
    \item[ZTA] Paradigma de segurança que elimina confiança implícita baseada em perímetro de rede, requerindo verificação contínua de identidade, dispositivo e contexto para cada acesso a recursos. Implementações modernas empregam ML para análise comportamental de usuários e dispositivos (UEBA).
\end{description}

\input{apendice_estudos_final}
% \input{apendice_validacao_temporal}

\clearpage    

\bibliographystyle{IEEEtran}
\bibliography{references}

\EOD

\end{document}