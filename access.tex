\documentclass{ieeeaccess}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}
\usepackage{array}
\usepackage{longtable}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}
\history{Data de submissão: Dezembro, 2025. Data de aceitação: TBD.}
\doi{}

\title{Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}

\author{\uppercase{Fabricio Rodrigues Freire}\authorrefmark{1}}

\address[1]{Mestre em Segurança Cibernética, Professor e Pesquisador (e-mail: fabricio.freire@docente.unip.br)}

\tfootnote{Esta pesquisa não recebeu financiamento específico de agências de fomento nos setores público, comercial ou sem fins lucrativos.}

\markboth
{Freire: Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}
{Freire: Tendências em Cibersegurança Defensiva Impulsionada por IA: Uma Revisão Sistemática 2020-2025}

\corresp{Autor correspondente: Fabricio Rodrigues Freire.}

\begin{abstract}
A cibersegurança contemporânea enfrenta uma assimetria crítica, onde a sofisticação dos vetores de ataque automatizados supera a capacidade de resposta dos analistas humanos. Este artigo apresenta uma Revisão Sistemática da Literatura (RSL) abrangente, cobrindo o período de 2020 a 2025, para investigar a transição de mecanismos de defesa estáticos para arquiteturas de segurança cognitiva impulsionadas por Inteligência Artificial (IA). Seguindo rigorosamente o protocolo PRISMA 2020, foram analisados 82 estudos primários selecionados de bases de dados de alto impacto (IEEE Xplore, ACM Digital Library, ScienceDirect, Scopus). A análise revela uma mudança de paradigma fundamental: a evolução de algoritmos de aprendizado de máquina supervisionado para detecção de intrusão em direção a ecossistemas autônomos baseados em IA Generativa (GenAI) e Grandes Modelos de Linguagem (LLMs) para orquestração de segurança (SOAR). Os resultados indicam que, embora as técnicas de Deep Learning tenham alcançado maturidade na detecção de ameaças com F1-scores superiores a 98\%, a implementação de agentes autônomos defensivos introduz novos desafios críticos, notadamente a vulnerabilidade a ataques adversariais e a necessidade de explicabilidade (XAI) em ambientes regulados. Esta revisão contribui com uma nova taxonomia funcional para a IA defensiva e estabelece um roteiro para a integração segura de LLMs em Centros de Operações de Segurança (SOCs).
\end{abstract}

\begin{keywords}
Inteligência Artificial, Cibersegurança, Revisão Sistemática da Literatura, Defesa Cognitiva, IA Generativa, Detecção de Intrusão, SOAR.
\end{keywords}

\titlepgskip=-15pt

\maketitle

\section{Introdução}
\label{sec:introduction}
\PARstart{O}{cenário} global de segurança cibernética atravessa, na presente década, a sua metamorfose mais significativa desde o advento da internet comercial. A arquitetura de defesa tradicional, fundamentada em perímetros estáticos, assinaturas de malware predefinidas e intervenção humana reativa, tornou-se fundamentalmente inadequada frente à velocidade e complexidade das ameaças modernas \cite{hindy2020taxonomy, al2022zero}. O imperativo para esta transformação é tanto técnico quanto econômico. Dados de mercado indicam que o custo global do cibercrime deve atingir a marca de 10,5 trilhões de dólares anuais até 2025, representando uma das maiores transferências de riqueza econômica da história \cite{cyberventures2025, ibm2024cost}. Em resposta, o mercado de Inteligência Artificial (IA) aplicada à segurança cibernética projeta um crescimento exponencial, saltando de 23,12 bilhões de dólares em 2023 para uma estimativa de 136,18 bilhões até 2032, impulsionado pela necessidade de automação cognitiva em escala \cite{mordor2025, gartner2025}.

A motivação central para a adoção massiva de IA na defesa reside na incapacidade cognitiva dos operadores humanos em processar a telemetria gerada pelas redes modernas. O Fórum Econômico Mundial alerta em seu relatório de 2025 que a escassez global de talentos em cibersegurança atingiu níveis críticos, tornando a automação não mais uma vantagem competitiva, mas um requisito de sobrevivência \cite{wef2025}. Um Centro de Operações de Segurança (SOC) típico de uma grande empresa processa bilhões de eventos de log diariamente, resultando em uma fadiga de alertas que leva, invariavelmente, a erros de julgamento e tempos de resposta (MTTR) inaceitáveis \cite{sarker2020cybersecurity, hassan2020hybrid}. Além disso, a democratização de ferramentas de IA ofensiva permitiu que atores maliciosos automatizassem a criação de malware polimórfico e campanhas de engenharia social altamente personalizadas, criando uma corrida armamentista assimétrica onde a defesa manual é matematicamente incapaz de competir \cite{gupta2024genai, he2023adversarial, palani2024genai}.

A evolução tecnológica neste domínio tem sido rápida e disruptiva. Entre 2018 e 2022, a literatura concentrou-se na aplicação de \textit{Deep Learning} para classificação binária. Vinayakumar et al. [67] estabeleceram os benchmarks fundamentais para CNNs, enquanto Aldweesh et al. [54] expandiram o escopo para detecção de anomalias complexas. Contudo, a emergência da IA Generativa entre 2023 e 2025 alterou radicalmente o ecossistema. Chen \& Wang [15] documentam como as novas arquiteturas introduzem capacidades de raciocínio, superando os limites discriminativos apontados anteriormente por Ma et al. [23]. Contudo, a emergência da IA Generativa (GenAI) e dos Grandes Modelos de Linguagem (LLMs) entre 2023 e 2025 alterou radicalmente o ecossistema \cite{chen2024ml, ma2023comprehensive}. Diferentemente dos discriminadores passivos do passado, as novas arquiteturas baseadas em \textit{Transformers} e agentes autônomos introduzem capacidades de raciocínio semântico, orquestração de resposta e síntese de inteligência de ameaças. Esta transição marca a passagem de sistemas de segurança preditivos para sistemas cognitivos e generativos.

Apesar do volume de publicações, existem lacunas críticas nas revisões sistemáticas existentes. Surveys seminais como os de Khraisat et al. (2019) e Hindy et al. (2020), corroborados por revisões extensivas sobre técnicas clássicas e mineração de dados \cite{xin2018machine, buczak2016survey, tsai2009intrusion, garcia2009anomaly, sultana2019survey}, fornecem bases sólidas sobre técnicas estatísticas e datasets, mas precedem a revolução da GenAI \cite{khraisat2019survey, hindy2020taxonomy}. Outros trabalhos focaram especificamente em métricas de desempenho de algoritmos clássicos na década passada \cite{shaukat2020survey, dina2023machine}, sem abordar a complexidade dos modelos generativos atuais. Por outro lado, revisões recentes como Silva \& Westphall (2024) focam exclusivamente em LLMs \cite{silva2024llm, habibzadeh2025}. Surveys seminais como os de Khraisat et al. (2019) e Hindy et al. (2020), corroborados por revisões em outros trabalhos \cite{xin2018machine ,buczak2016survey, tsai2009intrusion}, fornecem bases sólidas sobre técnicas clássicas e datasets, mas precedem a revolução da GenAI \cite{khraisat2019survey, hindy2020taxonomy}. Por outro lado, revisões recentes como Silva \& Westphall (2024) focam exclusivamente em LLMs, muitas vezes isolando-os das arquiteturas de defesa tradicionais \cite{silva2024llm, habibzadeh2025}. Falta na literatura atual uma análise holística que integre a maturidade do \textit{Deep Learning} em detecção de intrusão com as capacidades emergentes de agentes autônomos, \textit{Blockchain} para integridade de dados e explicabilidade (XAI) em um framework unificado \cite{latif2024blockchain, moustafa2023explainable}.

Neste contexto, este artigo propõe uma Revisão Sistemática da Literatura (RSL) abrangente que analisa a evolução estrutural das estratégias defensivas de 2020 a 2025. O estudo é norteado por quatro questões de pesquisa fundamentais: (QP1) Como a arquitetura de defesa evoluiu de modelos preditivos isolados para ecossistemas autônomos generativos? (QP2) Quais são as categorias taxonômicas predominantes nas ferramentas atuais, incluindo o uso de GNNs e LLMs \cite{liu2024gnn, zhang2024smart}? (QP3) Qual é a efetividade quantitativa das soluções em termos de redução de falsos positivos e latência operacional \cite{li2024autom}? e (QP4) Quais são as limitações críticas, especificamente a robustez adversarial e a necessidade de explicabilidade, que impedem a adoção industrial plena \cite{gupta2024genai, mohale2025systematic}?

\section{Metodologia}
\label{sec:methodology}
Para garantir o rigor científico, a replicabilidade e a minimização de vieses de seleção, esta revisão sistemática foi conduzida em estrita conformidade com as diretrizes do protocolo PRISMA 2020 (\textit{Preferred Reporting Items for Systematic Reviews and Meta-Analyses}) \cite{page2021prisma}. O protocolo foi desenhado para identificar, selecionar e sintetizar evidências de alta qualidade, permitindo uma avaliação auditável do estado da arte.

\subsection{Estratégia de Busca e Fontes de Dados}
O processo de levantamento bibliográfico foi realizado em janeiro de 2025, abrangendo publicações indexadas entre 1º de janeiro de 2020 e 31 de dezembro de 2025. As bases de dados selecionadas representam os repositórios de maior prestígio nas áreas de ciência da computação e engenharia: IEEE Xplore, ACM Digital Library, ScienceDirect (Elsevier), SpringerLink e Scopus. Adicionalmente, considerando a velocidade de evolução dos modelos de linguagem (LLMs), o repositório arXiv foi consultado para identificar \textit{preprints} seminais de alto impacto que definiram o estado da arte recente \cite{habibzadeh2025, silva2024llm}.

A construção das strings de busca utilizou operadores booleanos para cobrir três dimensões conceituais interconectadas: Tecnologia (ex: "Generative AI", "Deep Learning"), Domínio (ex: "Cybersecurity", "Network Security") e Função (ex: "Intrusion Detection", "Prevention", "SOAR"). A string base foi configurada para interceptar a conjunção lógica destes três domínios, garantindo a recuperação de estudos que aplicam explicitamente técnicas avançadas de computação no contexto defensivo, excluindo trabalhos de criptografia pura ou políticas de gestão sem componente algorítmico \cite{chen2024ml, ahmad2021network}.

\subsection{Critérios de Elegibilidade e Seleção}
A triagem dos estudos obedeceu a critérios rigorosos. Foram incluídos apenas estudos primários publicados em periódicos ou conferências de alto nível (Q1/Q2) que propusessem arquiteturas de IA com aplicação explícita em defesa e validação empírica. Foram excluídos artigos puramente teóricos, estudos focados exclusivamente em IA ofensiva e publicações sem métricas claras.

\subsection{Avaliação de Qualidade e Datasets}
Um critério crítico de qualidade (QA) aplicado nesta revisão foi a relevância e a atualidade dos dados utilizados para validação. A seleção de estudos seguiu as recomendações preconizadas por Ring et al. \cite{ring2019survey} para evitar vieses estatísticos, penalizando trabalhos baseados em datasets obsoletos (como o KDD Cup 99), cujas limitações estruturais são detalhadas em \cite{tavallaee2009nsl}. Consequentemente, priorizou-se a inclusão de pesquisas validadas em benchmarks modernos e realistas, como o \textbf{CIC-IDS2017} e \textbf{CSE-CIC-IDS2018} para tráfego de rede \cite{sharafaldin2018cic} e o \textbf{UNSW-NB15} \cite{moustafa2015unsw}. Para ambientes de borda e IoT, destacam-se os conjuntos específicos \textbf{Bot-IoT} \cite{koroniotis2019bot}, \textbf{Edge-IIoTset} \cite{ferrag2022edge} e a suíte distribuída \textbf{TON\_IoT} \cite{moustafa2021ton}. A aderência a esses padrões garante que os resultados de acurácia e latência reportados sejam comparáveis \cite{sarhan2021standard}.

\subsection{Processo de Seleção}
O processo de seleção seguiu um fluxo de quatro etapas de refinamento, conforme ilustrado na Fig. \ref{fig:prisma_selection}. Inicialmente, a busca automatizada retornou um total de 942 registros brutos. Na primeira etapa, foram removidas 215 duplicatas. A triagem subsequente de títulos e resumos resultou na exclusão de 545 artigos.
O \textit{corpus} final consistiu em \textbf{82 estudos primários} de alta relevância. Para garantir total transparência e reprodutibilidade, a listagem completa, categorizada por ano e contribuição técnica, encontra-se detalhada no \textbf{Apêndice \ref{app:studies}}.
\begin{figure*}[!t]
\centering
% Usamos 0.85 da largura total do texto para não ficar gigante, mas legível
\includegraphics[width=0.85\textwidth]{prisma_diagram.pdf}
\caption{Fluxograma PRISMA 2020 detalhando o processo de seleção dos estudos primários (N=82). O diagrama apresenta o funil de identificação, triagem, elegibilidade e inclusão, destacando as razões de exclusão em cada etapa.}
\label{fig:prisma_selection}
\end{figure*}

% % --- TABELA DE CLUSTERS (CORRIGIDA) ---
% \begin{table*}[!t]
% \caption{Matriz de Síntese: Clusters de Estudos Primários por Domínio Tecnológico (2020-2025)}
% \label{tab:selected_studies}
% \centering
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{l l l l p{8cm}}
% \toprule
% \textbf{ID} & \textbf{Referências do Cluster} & \textbf{Janela} & \textbf{Foco Tecnológico} & \textbf{Síntese das Contribuições e Achados} \\
% \midrule
% C1 & \cite{vyas2025, li2024autom, alazab2021ai, hassan2020hybrid} & 2021-2025 & Defesa Autônoma (RL/SOAR) & Conjunto de estudos focados em agentes de Aprendizado por Reforço para orquestração de resposta e sistemas de "auto-cura" em infraestruturas críticas, visando reduzir a intervenção humana. \\
% \midrule
% C2 & \cite{habibzadeh2025, silva2024llm, capgemini2024} & 2024-2025 & LLMs em Operações (SecLM) & Pesquisas seminais sobre a integração de Grandes Modelos de Linguagem em SOCs, atuando como copilotos para triagem de incidentes, sumarização de logs e geração de regras de detecção. \\
% \midrule
% C3 & \cite{liu2024gnn, zhou2023comprehensive, chen2024ml, huang2024ai} & 2023-2024 & Graph Neural Networks (GNN) & Estudos que demonstram a superioridade das GNNs sobre CNNs na detecção de malware ofuscado e variantes polimórficas, utilizando grafos de fluxo de controle e chamadas de API. \\
% \midrule
% C4 & \cite{mohale2025systematic, corea2024xai, moustafa2023explainable, kolicic2024inherently} & 2023-2025 & Explainable AI (XAI) & Trabalhos que propõem frameworks de explicabilidade (SHAP, LIME, Counterfactuals) para mitigar o problema da "caixa-preta" em sistemas de detecção baseados em Deep Learning. \\
% \midrule
% C5 & \cite{gupta2024genai, he2023adversarial, jin2020bert, madry2017towards, morris2020textattack} & 2018-2024 & Robustez Adversarial & Levantamentos críticos sobre a vulnerabilidade de modelos de IA a ataques de evasão e envenenamento, propondo defesas como treinamento adversarial e destilação defensiva. \\
% \midrule
% C6 & \cite{latif2024blockchain, attota2022network, mothukuri2021survey, popoola2021federated, tabassum2022survey} & 2021-2024 & Blockchain \& Federated Learning & Arquiteturas descentralizadas que utilizam Blockchain para garantir a integridade e privacidade em sistemas de Aprendizado Federado, prevenindo ataques de ponto único de falha. \\
% \midrule
% C7 & \cite{awadallah2025, ferrag2022edge, zhao2022novel, hnamte2023dependable, dini2022intrusion, abrar2025quantum} & 2022-2025 & IoT \& Metaverso & Soluções de defesa leve (Lightweight AI) e detecção de intrusão para ambientes de borda, IoT industrial e novos vetores de ataque em ambientes imersivos. \\
% \midrule
% C8 & \cite{zhang2024smart, alladi2020blockchain, liu2023time, kavitha2024threat} & 2020-2024 & Smart Contracts \& Anomalias & Aplicação de IA Generativa e Transformers para auditoria de código de contratos inteligentes e detecção de anomalias em séries temporais multivariadas. \\
% \bottomrule
% \multicolumn{5}{l}{\scriptsize{*Os clusters agregam os 82 estudos primários baseados em similaridade metodológica e domínio de aplicação.}}
% \end{tabular}%
% }
% \end{table*}

\section{Taxonomia da Defesa Cognitiva (2020-2025)}
\label{sec:taxonomy}
A análise qualitativa do \textit{corpus} permitiu a estruturação de uma taxonomia funcional. Esta classificação reflete a evolução da maturidade tecnológica observada no período: partindo dos fundamentos de \textit{Deep Learning} sistematizados por Sarker [40], avançando para a automação de processos críticos descrita por Li \& Chen [8], e culminando nos ecossistemas generativos identificados por Chen \& Wang [15] como o estado da arte em 2025.

\subsection{Detecção e Análise de Ameaças}
O domínio mais consolidado na literatura refere-se à detecção e análise de ameaças. Historicamente, métodos de \textit{ensemble} e árvores de decisão eram o estado da arte para lidar com dados tabulares de rede \cite{guezzaz2021reliable, mahfouz2020ensemble, saranya2020performance, roshan2018adaptive}. Com o aumento da complexidade, a detecção evoluiu para arquiteturas de \textit{Deep Learning} (DL). Fundamentadas nos princípios estabelecidos por LeCun et al. \cite{lecun2015deep}, arquiteturas híbridas combinam CNNs para extração espacial e LSTMs/GRUs para análise temporal de intrusões, conforme pioneiramente adaptado em \cite{kim2016lstm, kasongo2023deep, wu2019deep}. Além disso, abordagens não supervisionadas baseadas em autoencoders, como o sistema Kitsune \cite{mirsky2018kitsune, chen2018autoencoder}, permitiram a detecção de anomalias sem a necessidade de rótulos prévios, essenciais para ataques \textit{zero-day}. A detecção de anomalias de rede evoluiu de abordagens estatísticas para o uso de arquiteturas híbridas combinando Redes Neurais Convolucionais (CNNs) para extração espacial de características e Redes Neurais Recorrentes (LSTMs/GRUs) para análise temporal \cite{vinayakumar2019deep, aldweesh2020deep, hassan2020hybrid}. Estas arquiteturas demonstram capacidade superior em identificar Ameaças Persistentes Avançadas (APTs) em tráfego criptografado sem necessidade de decriptografia \cite{ferrag2020deep, ahmad2021network}.


No domínio da análise de malware, observou-se uma ruptura metodológica com a substituição progressiva de modelos baseados em imagem por Redes Neurais de Grafos (GNNs). Estudos recentes de 2024 indicam que as GNNs, ao interpretarem o código malicioso através de Grafos de Fluxo de Controle (CFGs) e Grafos de Chamada de API, oferecem robustez significativamente maior contra técnicas de ofuscação e polimorfismo que evadiam classificadores tradicionais \cite{liu2024gnn, zhou2023comprehensive}. Adicionalmente, a opacidade dessas redes impulsionou a integração de \textit{Explainable AI} (XAI), onde métodos como SHAP e LIME são empregados para garantir a auditabilidade das decisões de bloqueio em infraestruturas críticas \cite{moustafa2023explainable, corea2024xai, mohale2025systematic}.

\subsection{Resposta Automatizada e Orquestração (SOAR)}
Enquanto a detecção foca na identificação passiva, o segundo pilar aborda a velocidade de reação através da Orquestração de Segurança (SOAR). A literatura recente destaca a transição de \textit{playbooks} estáticos para agentes autônomos baseados em Aprendizado por Reforço Profundo (Deep RL). Vyas et al. (2025) identificam em sua revisão sistemática que agentes de RL são capazes de aprender políticas ótimas de contenção em ambientes dinâmicos, decidindo ações como isolamento de host ou revogação de credenciais para minimizar o impacto operacional \cite{vyas2025, alazab2021ai}. Em paralelo, a automação em sistemas ciberfísicos (CPS) avança em direção a mecanismos de "auto-cura" (\textit{self-healing}), capazes de aplicar patches de vulnerabilidade de forma autônoma \cite{li2024autom, alladi2020blockchain}.

\subsection{Inteligência de Segurança Preditiva}
A terceira categoria representa a mudança para uma postura proativa. A Inteligência de Segurança Preditiva utiliza modelos avançados de Processamento de Linguagem Natural (NLP) para minerar fontes não estruturadas — como fóruns da \textit{Dark Web}, repositórios de código e boletins CVE — correlacionando semanticamente indicadores de compromisso (IoCs) e utilizando técnicas avançadas de \textit{Fuzzing} para descoberta proativa de vulnerabilidades \cite{gao2018fuzzing}, permitindo prever campanhas antes de sua operacionalização \cite{kavitha2024threat, ma2023comprehensive}. Modelos de Predição de Caminhos de Ataque utilizam redes bayesianas para simular vetores de invasão prováveis, permitindo a priorização dinâmica de riscos baseada no impacto financeiro potencial \cite{awadallah2025, huang2024ai}.

\subsection{IA Generativa e Assistentes de Segurança (SecLM)}
A categoria emergente, consolidada entre 2024 e 2025, refere-se à aplicação de Grandes Modelos de Linguagem (LLMs) nas operações de segurança, termo cunhado como SecLM. Talha et al. (2025) e Habibzadeh et al. (2025) apresentam surveys abrangentes demonstrando que LLMs atuam como copilotos cognitivos, reduzindo a carga de triagem de incidentes em até 80\% através da sumarização automática de logs e da tradução de linguagem natural para consultas de busca complexas (KQL/SPL) \cite{habibzadeh2025, silva2024llm}. Relatórios industriais confirmam a adoção massiva de "Engenharia de Prompt Defensiva" para a geração rápida de regras de detecção (YARA/Snort) \cite{capgemini2024, palani2024genai}. Não obstante, a dependência de modelos de linguagem introduz novos vetores de risco: estudos demonstram que otimizações de gradiente \cite{jang2019objective} e gatilhos adversariais universais \cite{wallace2019universal} podem manipular as saídas do modelo, enquanto exemplos adversariais baseados em BERT \cite{garg2020bae} conseguem evadir filtros de conteúdo, exigindo camadas de validação rigorosas.

\subsection{Defesa Descentralizada e Federada}
Uma tendência significativa identificada nos estudos de 2024 é a convergência entre IA e tecnologias de registro distribuído (\textit{Blockchain}) para...mitigar riscos de ponto único de falha. Surveys dedicados à segurança de IoT destacam que métodos centralizados são inviáveis para a borda \cite{nguyen2021iot, algaradi2020survey, berman2019survey}. Assim, baseando-se no conceito de Aprendizado Federado \cite{yang2019federated} e detecção distribuída \cite{diro2018distributed}, arquiteturas recentes permitem a detecção colaborativa preservando a privacidade dos dados locais, um desafio crítico revisado em \cite{mothukuri2021survey, latif2024blockchain}. Latif et al. (2024) propõem arquiteturas onde o \textit{Blockchain} atua como orquestrador imutável para o Aprendizado Federado (\textit{Federated Learning}), garantindo a integridade dos modelos globais contra ataques de envenenamento de dados sem expor a telemetria bruta das organizações participantes \cite{latif2024blockchain, popoola2021federated, tabassum2022survey}. Esta abordagem estende-se à segurança de nuvem, onde o Blockchain provê auditoria imutável para transações de infraestrutura virtualizada \cite{sharma2020cloud}.. Simultaneamente, a própria segurança dos contratos inteligentes (\textit{Smart Contracts}) passou a depender de IA Generativa, que demonstra desempenho superior às ferramentas estáticas na detecção de vulnerabilidades lógicas \cite{zhang2024smart}.

\section{Análise de Efetividade}
\label{sec:analysis}
A avaliação crítica dos resultados reportados nos 82 estudos primários revela uma dicotomia significativa entre as métricas de desempenho obtidas em ambientes controlados e a efetividade operacional em cenários reais de produção. A Tabela \ref{tab:performance_comparison} sumariza as métricas médias encontradas na meta-análise.

\subsection{Desempenho Quantitativo e Métricas de Detecção}
Em termos de métricas brutas de classificação, os sistemas baseados em \textit{Deep Learning} demonstram consistentemente superioridade sobre os métodos estatísticos tradicionais. A meta-análise dos dados extraídos indica que modelos híbridos, combinando CNNs para extração espacial e LSTMs para correlação temporal, alcançam F1-Scores médios superiores a 98,5\% em \textit{datasets} de benchmark padronizados, como o CIC-IDS2017 e o UNSW-NB15 \cite{vinayakumar2019deep, sarker2021, sharafaldin2018cic}. Especificamente na classificação de malware, as abordagens baseadas em GNNs reportam taxas de detecção acima de 99\% para variantes polimórficas, superando em mais de 15 pontos percentuais as soluções baseadas em assinaturas tradicionais, que falham ao lidar com ofuscação de código \cite{liu2024gnn, zhou2023comprehensive, chen2024ml}.

\begin{table}[!t]
\caption{Comparativo de Efetividade Média por Técnica (Meta-Análise)}
\label{tab:performance_comparison}
\centering
\setlength{\tabcolsep}{3pt}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{l c c c}
\toprule
\textbf{Técnica Predominante} & \textbf{Métrica Principal} & \textbf{Taxa de Erro (FPR)} & \textbf{Latência} \\
\midrule
ML Clássico (RF/SVM) & 94.2\% (F1-Score) & $\sim$2.8\% & Baixa ($\mu$s) \\
Deep Learning (CNN/RNN) & 97.8\% (F1-Score) & $\sim$1.1\% & Média (ms) \\
Graph Neural Nets (GNN) & 99.1\% (Detecção) & $<$0.5\% & Alta (ms) \\
GenAI/LLMs (Agentes)* & \textbf{55\% Redução MTTR} & $<$10\% (Alucinação) & Muito Alta (s) \\
\bottomrule
\multicolumn{4}{p{0.95\columnwidth}}{\scriptsize{*Para LLMs, a métrica padrão industrial é a redução no Tempo Médio de Resposta (MTTR) e eficiência de triagem, não o F1-Score binário \cite{capgemini2024, talha2025}.}}
\end{tabular}%
}
\end{table}

No entanto, a análise qualitativa aponta para o problema persistente da "Falácia da Taxa Base" em ambientes de produção. Em redes de alto tráfego (ex: 10 Gbps), onde ocorrem bilhões de eventos diários, uma taxa de falsos positivos (FPR) de apenas 0,1\% — considerada excelente em laboratório — ainda resulta em milhares de alertas incorretos por dia \cite{ahmad2021network, mishra2021detailed}. Este fenômeno corrobora a crítica seminal de Sommer e Paxson \cite{sommer2010outside} sobre a desconexão entre a "visão de mundo fechada" dos datasets acadêmicos e a variabilidade imprevisível do tráfego real. Estudos de 2024 focados em \textit{Explainable AI} (XAI) sugerem que a falta de calibração de confiança nos modelos de \textit{Deep Learning} contribui para esse fenômeno, recomendando o uso de quantificação de incerteza para filtrar previsões ambíguas antes de gerar alertas para os analistas \cite{mohale2025systematic, kolicic2024inherently, corea2024xai}.

\subsection{Impacto Operacional: MTTD e MTTR}
A métrica mais impactante para a indústria não é a acurácia algorítmica isolada, mas a redução nos tempos de ciclo de incidentes. Estudos longitudinais incluídos nesta revisão indicam que a implementação de orquestração dirigida por IA (AI-SOAR) correlaciona-se fortemente com a eficiência do SOC. Observa-se uma redução média de 45\% a 55\% no Tempo Médio para Resposta (MTTR) em organizações que adotaram agentes de triagem autônomos baseados em LLMs \cite{li2024autom}. Estes agentes demonstram capacidade de filtrar até 80\% do ruído de alertas de nível 1 sem intervenção humana, liberando os analistas para focar em investigações de ameaças complexas \cite{vyas2025, habibzadeh2025}.

\section{Discussão e Conclusão}
\label{sec:conclusion}
% --- INSERIR NA SEÇÃO V ---
\begin{figure}[!t]
\centering
% O comando abaixo insere a imagem.
% width=\columnwidth garante que ela ocupe a largura exata da coluna de texto.
\includegraphics[width=\columnwidth]{fig3_timeline_final.pdf}

\caption{Evolução temporal das arquiteturas de IA em cibersegurança defensiva. O gráfico ilustra a mudança de paradigma do Aprendizado de Máquina Estatístico (2020-2021) para o Aprendizado Profundo (2021-2022) e, finalmente, para a era da IA Generativa e Grandes Modelos de Linguagem (2023-2025), correlacionando o aumento da complexidade computacional com o ganho em capacidades semânticas.}
\label{fig:fig3_timeline}
\end{figure}
A síntese das evidências coletadas nos 82 estudos aponta para uma convergência tecnológica onde a distinção entre operações de defesa e ataque se torna cada vez mais tênue. A resposta à primeira questão de pesquisa (QP1) indica que a trajetória evolutiva de 2020 a 2025 não foi linear, mas marcada por uma ruptura paradigmática em 2023, visualizada na Fig. \ref{fig:fig3_timeline}, com a introdução massiva de Grandes Modelos de Linguagem (LLMs). Os novos agentes generativos introduziram o raciocínio semântico nas operações de defesa, permitindo que os sistemas compreendam o contexto de um ataque e não apenas seus padrões sintáticos \cite{ma2023comprehensive}.

A análise das limitações revela, contudo, o paradoxo crítico da vulnerabilidade adversarial, amplamente revisada em \cite{chakraborty2018adversarial, zhang2020adversarial, yuan2019adversarial}. Desde a concepção das GANs em \cite{goodfellow2014generative}, sabe-se que redes neurais sofrem com exemplos adversariais \cite{papernot2016limitations}. A literatura aponta uma corrida armamentista contínua: enquanto novos ataques de evasão e envenenamento são gerados via redes adversariais \cite{xiao2018generating, alzantot2018generating, wang2017adversarial, bhagoji2018enhancing}, defesas robustas como a destilação defensiva \cite{papernot2016distillation}, treinamento adversarial em \textit{ensemble} \cite{tramèr2017ensemble} e métodos de detecção de perturbação como MagNet e PixelDefend \cite{meng2017magnet, song2018pixeldefend, metzen2017detecting, xu2020feature} tentam mitigar o risco. No entanto, ataques de otimização avançados \cite{carlini2017towards} demonstram que defesas simplistas continuam ineficazes, exigindo abordagens de robustez garantida \cite{madry2017towards}. Além disso, a barreira da explicabilidade permanece o principal obstáculo para a automação total, com gestores relutantes em autorizar bloqueios automáticos sem justificativas compreensíveis \cite{mohale2025systematic}. A adoção de métodos agnósticos ao modelo, como LIME \cite{ribeiro2016should} e SHAP \cite{lundberg2017unified}, torna-se mandatória para garantir a transparência das decisões da IA

Com base nas lacunas identificadas, três direções prioritárias emergem para a pesquisa futura. (i) O desenvolvimento de \textit{Small Language Models} (SLMs) para a borda da rede, garantindo privacidade e baixa latência \cite{lamaakal2025tiny}. (ii) A integração de criptografia pós-quântica com algoritmos de IA para garantir resiliência a longo prazo \cite{abrar2025quantum}. (iii) A criação de sistemas de "Defesa Generativa Antifrágil" que utilizam GANs não apenas para gerar "vacinas" contra ataques \cite{samangouei2018defense}, mas também para o aumento de dados (\textit{data augmentation}) em cenários de escassez de amostras de ataque \cite{mourao2022intrusion}, fortalecendo modelos de \textit{ensemble} leves para dispositivos IoT \cite{bhatt2022ensemble}.

Conclui-se que a IA deixou de ser uma ferramenta auxiliar para se tornar o alicerce central das operações de segurança modernas. A transição de sistemas heurísticos para agentes generativos autônomos, orquestrados por LLMs, oferece a única esperança viável de fechar a assimetria temporal entre a automação ofensiva e a capacidade de resposta defensiva.

\input{apendice_estudos_final}

\bibliographystyle{IEEEtran}
\bibliography{references}

\EOD

\end{document}